{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FkI6JV21HdWy"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "Btjy4-h5Gp8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Files"
      ],
      "metadata": {
        "id": "06nQT4xN4Yw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE4yAQHe5jnU",
        "outputId": "36a11ba9-814e-4023-d4c5-bb34a2cc2a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import os\n",
        "\n",
        "file_id = '1_Xo2vU82JSSadBdD1Kb7iImHnEYdoFGh'\n",
        "output = 'open.zip' # ì €ì¥í•  íŒŒì¼ ì´ë¦„\n",
        "\n",
        "# 'output'ìœ¼ë¡œ ì§€ì •ëœ íŒŒì¼ì´ í˜„ì¬ ê²½ë¡œì— ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš°ì—ë§Œ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰\n",
        "if not os.path.exists(output):\n",
        "    print(f\"'{output}' íŒŒì¼ì´ ì—†ì–´ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "    gdown.download(id=file_id, output=output)\n",
        "else:\n",
        "    print(f\"'{output}' íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrY5NWym633Z",
        "outputId": "e436dfbd-e9f7-44cc-c543-e5dca10859f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'open.zip' íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -qq '/íŒŒì¼ ê²½ë¡œ/íŒŒì¼ëª….zip' -d 'ì €ì¥í•  dir ìœ„ì¹˜ ê²½ë¡œ'\n",
        "!unzip -qq '/content/open.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "bn7qrkQ29SJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a7fafa-d2a0-4ba5-8127-8e8616f947a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "SZuHPwZHGsCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60myyOqfGNYD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import glob\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import holidays\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixed RandomSeed & Setting Hyperparameter"
      ],
      "metadata": {
        "id": "Z_dVtm98Gu2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "WykYlxUmGvqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)    # 1. íŒŒì´ì¬ ë‚´ì¥ random ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
        "    np.random.seed(seed)    # 2. NumPy ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë‚œìˆ˜ ìƒì„± ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
        "    torch.manual_seed(seed)    # 3. PyTorchì˜ CPU ì—°ì‚°ì— ëŒ€í•œ ë‚œìˆ˜ ìƒì„± ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)    # 4. íŒŒì´ì¬ì˜ í•´ì‹œ ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ ë“±ì˜ ìˆœì„œë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "    # 5. CUDA (GPU) ì‚¬ìš©ì´ ê°€ëŠ¥í•œ ê²½ìš°, GPU ê´€ë ¨ ì‹œë“œ ë° ì„¤ì •ì„ ê³ ì •í•©ë‹ˆë‹¤.\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)    # 5-1. í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ GPUì˜ ë‚œìˆ˜ ìƒì„± ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
        "        torch.cuda.manual_seed_all(seed)    # 5-2. ì—¬ëŸ¬ ê°œì˜ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ëª¨ë“  GPUì˜ ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
        "        torch.backends.cudnn.deterministic = True   # 5-3. cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•­ìƒ ê²°ì •ì ì¸(deterministic) ì•Œê³ ë¦¬ì¦˜ë§Œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "        torch.backends.cudnn.benchmark = False  # 5-4. cuDNNì˜ ë²¤ì¹˜ë§ˆí¬ ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.\n",
        "\n",
        "set_seed(42)    # ìœ„ì—ì„œ ì •ì˜í•œ í•¨ìˆ˜ë¥¼ seed ê°’ 42ë¡œ ì‹¤í–‰í•˜ì—¬ ì½”ë“œ ì „ì²´ì˜ ì¬í˜„ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "dbE2YGZJGvXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "LOOKBACK=28: ê³¼ê±° 28ì¼ì¹˜ ë°ì´í„°ë¥¼ ë³´ê³ \n",
        "PREDICT=7: ë¯¸ë˜ 7ì¼ì¹˜ë¥¼ ì—ì¸¡\n",
        "BATCH_SIZE=16: í•œë²ˆì— 16ê°œì˜ dataë¥¼ ë¬¶ì–´ í•™ìŠµ\n",
        "EPOCHS=50: ì „ì²´ ë°ì´í„°ë¥¼ 50ë²ˆ ë°˜ë³µí•™ìŠµ\n",
        "\"\"\"\n",
        "LOOKBACK, PREDICT, BATCH_SIZE, EPOCHS = 28, 7, 16, 50\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "YjZTezKNGzdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "awCUrimaG05S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('./train/train.csv')"
      ],
      "metadata": {
        "id": "HyvYhNW4G2Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import holidays\n",
        "\n",
        "def dataPreProcessing(df):\n",
        "    # 1. ì—´ ì´ë¦„ ì •ë¦¬\n",
        "    df = df.rename(columns={\n",
        "        'ì˜ì—…ì¼ì': 'date_time',\n",
        "        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': 'market_menu',\n",
        "        'ë§¤ì¶œìˆ˜ëŸ‰': 'sales_amount'\n",
        "    }) if 'ì˜ì—…ì¼ì' in df.columns else df\n",
        "\n",
        "    # 2. ë‚ ì§œ íŒŒìƒ\n",
        "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
        "    df['weekday'] = df['date_time'].dt.weekday\n",
        "    df['weekend'] = df['weekday'].isin([5, 6]).astype(int)\n",
        "    df['month'] = df['date_time'].dt.month\n",
        "    df['dayofweek'] = df['date_time'].dt.dayofweek\n",
        "    df['day'] = df['date_time'].dt.day\n",
        "\n",
        "    # 3. ê³µíœ´ì¼\n",
        "    kr_holidays = holidays.KR()\n",
        "    df['holiday'] = df['date_time'].dt.date.apply(lambda d: int(d in kr_holidays))\n",
        "\n",
        "    # 4. ë°©í•™ ì‹œì¦Œ (1,2,7,8ì›”)\n",
        "    df['vacation_season'] = df['month'].isin([1, 2, 7, 8]).astype(int)\n",
        "\n",
        "    # 5. ë©”ë‰´ëª… ë¶„í•´\n",
        "    df[['store_name', 'menu_name']] = df['market_menu'].str.split('_', n=1, expand=True)\n",
        "\n",
        "    # 6. ì‚¬ìš©ìœ í˜• ì¶”ì •\n",
        "    def classify_usage_type(menu):\n",
        "        if pd.isna(menu): return 'ê¸°íƒ€'\n",
        "        if 'ì–´ë¦°ì´' in menu: return 'ì–´ë¦°ì´'\n",
        "        elif re.search(r'ë‹¨ì²´|í”Œë˜í„°|ë¬´ì œí•œ|[3-9]ì¸|ì¸ë¶„|ì„¸íŠ¸', str(menu)): return 'ë‹¨ì²´'\n",
        "        elif '2ì¸' in menu: return 'ì»¤í”Œ'\n",
        "        elif '1ì¸' in menu or 'ë‹¨í’ˆ' in menu or 'Gls' in menu: return '1ì¸'\n",
        "        else: return 'ì¼ë°˜'\n",
        "\n",
        "    df['usage_type'] = df['menu_name'].apply(classify_usage_type)\n",
        "\n",
        "    # 7. ê³ ê¸‰ ë©”ë‰´ ì—¬ë¶€\n",
        "    df['is_premium'] = df['menu_name'].str.contains('í•œìš°|í”„ë¦¬ë¯¸ì—„|ìˆ˜ì œ|íŠ¹ì„ |ì™€ì¸').fillna(False).astype(int)\n",
        "\n",
        "    # 10. ë¼ë²¨ ì¸ì½”ë”© (ì‚¬ìš©ìœ í˜•)\n",
        "    usage_map = {'1ì¸': 0, 'ì»¤í”Œ': 1, 'ë‹¨ì²´': 2, 'ì–´ë¦°ì´': 3, 'ì¼ë°˜': 4, 'ê¸°íƒ€': 5}\n",
        "    df['usage_type_encoded'] = df['usage_type'].map(usage_map).fillna(5).astype(int)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "dP_9M_w8TaD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ìƒˆë¡œ ì¶”ê°€: ê·¸ë£¹ë³„ ì‹œê³„ì—´ í”¼ì²˜\n",
        "def add_ts_features(df, lags=(1,7,14), roll_window=7):\n",
        "    df = df.sort_values(['market_menu','date_time']).copy()\n",
        "    g = df.groupby('market_menu')['sales_amount']\n",
        "\n",
        "    for lag in lags:\n",
        "        df[f'lag_{lag}'] = g.shift(lag)\n",
        "\n",
        "    def _rmean(s): return s.shift(1).rolling(roll_window, min_periods=1).mean()\n",
        "    def _rstd(s):  return s.shift(1).rolling(roll_window, min_periods=1).std()\n",
        "\n",
        "    df['rolling_mean_7'] = df.groupby('market_menu')['sales_amount'].apply(_rmean).reset_index(level=0, drop=True)\n",
        "    df['rolling_std_7']  = df.groupby('market_menu')['sales_amount'].apply(_rstd).reset_index(level=0, drop=True)\n",
        "\n",
        "    # ìˆ˜ì¹˜ ê²°ì¸¡ ì•ˆì „ ì²˜ë¦¬ë§Œ ìµœì†Œë¡œ\n",
        "    num_cols = [c for c in df.columns if df[c].dtype.kind in 'if']\n",
        "    df[num_cols] = df[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    return df"
      ],
      "metadata": {
        "id": "68DSHmmm85ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def smape(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true, dtype=float)\n",
        "    y_pred = np.asarray(y_pred, dtype=float)\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    out = np.zeros_like(denom)\n",
        "    mask = denom > 0\n",
        "    out[mask] = np.abs(y_true[mask] - y_pred[mask]) / denom[mask]\n",
        "    return out.mean() * 100.0\n",
        "\n",
        "def add_days_since_last_sale(df):\n",
        "    # ì •ë ¬ & ë¼ë²¨ ì•ˆì „í™”\n",
        "    df = df.sort_values(['market_menu','date_time']).copy()\n",
        "    df['sales_amount'] = pd.to_numeric(df['sales_amount'], errors='coerce').fillna(0).clip(lower=0)\n",
        "\n",
        "    # ê·¸ë£¹ë³„ 'ë§ˆì§€ë§‰ ì–‘ìˆ˜ íŒë§¤ì¼'ì„ forward-fillë¡œ ê³„ì‚°\n",
        "    pos_date = df['date_time'].where(df['sales_amount'] > 0)\n",
        "    df['last_pos_date'] = pos_date.groupby(df['market_menu']).ffill()\n",
        "\n",
        "    # ì¼ìˆ˜ ê³„ì‚°(ë²¡í„°í™”): pandas Timedelta â†’ .dt.days ì‚¬ìš©\n",
        "    delta = df['date_time'] - df['last_pos_date']\n",
        "    df['days_since_last_sale'] = delta.dt.days.fillna(999).astype(int)\n",
        "\n",
        "    # ë³´ì¡° ì»¬ëŸ¼ ì •ë¦¬\n",
        "    df = df.drop(columns=['last_pos_date'])\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "aUtmAf6TW7BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df = dataPreProcessing(train)\n",
        "train_feat = add_ts_features(train_df)\n",
        "\n",
        "train_feat = add_days_since_last_sale(train_feat)\n",
        "train_df"
      ],
      "metadata": {
        "id": "WKdBtwjDTXoT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "1232972a-992f-400b-d0d9-824610e2b908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        date_time         market_menu  sales_amount  weekday  weekend  month  \\\n",
              "0      2023-01-01  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸             0        6        1      1   \n",
              "1      2023-01-02  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸             0        0        0      1   \n",
              "2      2023-01-03  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸             0        1        0      1   \n",
              "3      2023-01-04  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸             0        2        0      1   \n",
              "4      2023-01-05  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸             0        3        0      1   \n",
              "...           ...                 ...           ...      ...      ...    ...   \n",
              "102671 2024-06-11        í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼            12        1        0      6   \n",
              "102672 2024-06-12        í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼            10        2        0      6   \n",
              "102673 2024-06-13        í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼            14        3        0      6   \n",
              "102674 2024-06-14        í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼            12        4        0      6   \n",
              "102675 2024-06-15        í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼            60        5        1      6   \n",
              "\n",
              "        dayofweek  day  holiday  vacation_season  store_name menu_name  \\\n",
              "0               6    1        1                1  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ   1ì¸ ìˆ˜ì €ì„¸íŠ¸   \n",
              "1               0    2        0                1  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ   1ì¸ ìˆ˜ì €ì„¸íŠ¸   \n",
              "2               1    3        0                1  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ   1ì¸ ìˆ˜ì €ì„¸íŠ¸   \n",
              "3               2    4        0                1  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ   1ì¸ ìˆ˜ì €ì„¸íŠ¸   \n",
              "4               3    5        0                1  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ   1ì¸ ìˆ˜ì €ì„¸íŠ¸   \n",
              "...           ...  ...      ...              ...         ...       ...   \n",
              "102671          1   11        0                0       í™”ë‹´ìˆ²ì¹´í˜    í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼   \n",
              "102672          2   12        0                0       í™”ë‹´ìˆ²ì¹´í˜    í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼   \n",
              "102673          3   13        0                0       í™”ë‹´ìˆ²ì¹´í˜    í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼   \n",
              "102674          4   14        0                0       í™”ë‹´ìˆ²ì¹´í˜    í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼   \n",
              "102675          5   15        0                0       í™”ë‹´ìˆ²ì¹´í˜    í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼   \n",
              "\n",
              "       usage_type  is_premium  usage_type_encoded  \n",
              "0              ë‹¨ì²´           0                   2  \n",
              "1              ë‹¨ì²´           0                   2  \n",
              "2              ë‹¨ì²´           0                   2  \n",
              "3              ë‹¨ì²´           0                   2  \n",
              "4              ë‹¨ì²´           0                   2  \n",
              "...           ...         ...                 ...  \n",
              "102671         ì¼ë°˜           0                   4  \n",
              "102672         ì¼ë°˜           0                   4  \n",
              "102673         ì¼ë°˜           0                   4  \n",
              "102674         ì¼ë°˜           0                   4  \n",
              "102675         ì¼ë°˜           0                   4  \n",
              "\n",
              "[102676 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5b8af83-416b-49a5-9bab-5a32b4c457fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_time</th>\n",
              "      <th>market_menu</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>weekday</th>\n",
              "      <th>weekend</th>\n",
              "      <th>month</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>day</th>\n",
              "      <th>holiday</th>\n",
              "      <th>vacation_season</th>\n",
              "      <th>store_name</th>\n",
              "      <th>menu_name</th>\n",
              "      <th>usage_type</th>\n",
              "      <th>is_premium</th>\n",
              "      <th>usage_type_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ</td>\n",
              "      <td>1ì¸ ìˆ˜ì €ì„¸íŠ¸</td>\n",
              "      <td>ë‹¨ì²´</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-01-02</td>\n",
              "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ</td>\n",
              "      <td>1ì¸ ìˆ˜ì €ì„¸íŠ¸</td>\n",
              "      <td>ë‹¨ì²´</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ</td>\n",
              "      <td>1ì¸ ìˆ˜ì €ì„¸íŠ¸</td>\n",
              "      <td>ë‹¨ì²´</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ</td>\n",
              "      <td>1ì¸ ìˆ˜ì €ì„¸íŠ¸</td>\n",
              "      <td>ë‹¨ì²´</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ</td>\n",
              "      <td>1ì¸ ìˆ˜ì €ì„¸íŠ¸</td>\n",
              "      <td>ë‹¨ì²´</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102671</th>\n",
              "      <td>2024-06-11</td>\n",
              "      <td>í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>í™”ë‹´ìˆ²ì¹´í˜</td>\n",
              "      <td>í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼</td>\n",
              "      <td>ì¼ë°˜</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102672</th>\n",
              "      <td>2024-06-12</td>\n",
              "      <td>í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>í™”ë‹´ìˆ²ì¹´í˜</td>\n",
              "      <td>í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼</td>\n",
              "      <td>ì¼ë°˜</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102673</th>\n",
              "      <td>2024-06-13</td>\n",
              "      <td>í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>í™”ë‹´ìˆ²ì¹´í˜</td>\n",
              "      <td>í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼</td>\n",
              "      <td>ì¼ë°˜</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102674</th>\n",
              "      <td>2024-06-14</td>\n",
              "      <td>í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>í™”ë‹´ìˆ²ì¹´í˜</td>\n",
              "      <td>í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼</td>\n",
              "      <td>ì¼ë°˜</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102675</th>\n",
              "      <td>2024-06-15</td>\n",
              "      <td>í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼</td>\n",
              "      <td>60</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>í™”ë‹´ìˆ²ì¹´í˜</td>\n",
              "      <td>í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼</td>\n",
              "      <td>ì¼ë°˜</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102676 rows Ã— 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5b8af83-416b-49a5-9bab-5a32b4c457fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5b8af83-416b-49a5-9bab-5a32b4c457fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5b8af83-416b-49a5-9bab-5a32b4c457fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a7e84b40-ae44-4e02-84a3-6d45905d2de1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7e84b40-ae44-4e02-84a3-6d45905d2de1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a7e84b40-ae44-4e02-84a3-6d45905d2de1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f5355023-234e-4b08-976c-002dc55c4a33\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f5355023-234e-4b08-976c-002dc55c4a33 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#market_menuë³„ë¡œ ì‹œê³„ì—´ ìˆœì„œë¥¼ ìœ ì§€í•œ ì±„ë¡œ, ë§ˆì§€ë§‰ Nì¼ì„ validation setìœ¼ë¡œ ë–¼ì–´ëƒ„\n",
        "def time_series_train_val_split(df, val_days=7):\n",
        "\n",
        "    train_list = []\n",
        "    val_list = []\n",
        "\n",
        "    for menu, group in df.groupby('market_menu'):\n",
        "        group = group.sort_values('date_time')\n",
        "        if len(group) <= val_days:\n",
        "            train_list.append(group)\n",
        "            continue\n",
        "\n",
        "        train_group = group.iloc[:-val_days]\n",
        "        val_group = group.iloc[-val_days:]\n",
        "\n",
        "        train_list.append(train_group)\n",
        "        val_list.append(val_group)\n",
        "\n",
        "    train_df = pd.concat(train_list)\n",
        "    val_df = pd.concat(val_list)\n",
        "    return train_df, val_df\n"
      ],
      "metadata": {
        "id": "81zji3NdC9fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['sales_amount'] = (\n",
        "    pd.to_numeric(train_df['sales_amount'], errors='coerce')\n",
        "      .fillna(0)\n",
        "      .clip(lower=0)\n",
        ")"
      ],
      "metadata": {
        "id": "FPUjTyFqZaUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['weekend','holiday','vacation_season','usage_type_encoded',\n",
        "                'is_premium','lag_1','lag_7','lag_14','rolling_mean_7','rolling_std_7','days_since_last_sale']\n",
        "\n",
        "\n",
        "train_split, val_split = time_series_train_val_split(train_feat, val_days=7)\n",
        "\n",
        "# â† ì—¬ê¸°ì„œ ëª¨ë¸ ì •ì˜ + í•™ìŠµ\n",
        "model = XGBRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(train_split[feature_cols], train_split['sales_amount'])\n",
        "\n",
        "y_pred = model.predict(val_split[feature_cols])\n",
        "print(f\"Validation SMAPE: {smape(val_split['sales_amount'], y_pred):.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7WJBVe74Dlu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbaa1dc-dba1-429e-e7e2-410f9c2fea82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation SMAPE: 138.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ìµœê·¼ ë°ì´í„° ìˆœì„œì™€ ê¸°ê°„ì„ ê³ ë ¤\n",
        "def time_series_local_cv(df, feature_cols, n_splits=5, val_days=7):\n",
        "    df = df.sort_values(['market_menu', 'date_time'])\n",
        "    smape_scores = []\n",
        "\n",
        "    unique_dates = sorted(df['date_time'].unique())\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        split_point = unique_dates[-(val_days * (i + 1))]\n",
        "\n",
        "        train_split = df[df['date_time'] < split_point]\n",
        "        val_split = df[(df['date_time'] >= split_point) &\n",
        "                       (df['date_time'] < split_point + pd.Timedelta(days=val_days))]\n",
        "\n",
        "        model = XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42)\n",
        "        model.fit(train_split[feature_cols], train_split['sales_amount'])\n",
        "\n",
        "        y_pred = model.predict(val_split[feature_cols])\n",
        "        score = smape(val_split['sales_amount'], y_pred)\n",
        "        smape_scores.append(score)\n",
        "\n",
        "        print(f\"Fold {i+1} | Validation Date from {split_point.date()} â†’ SMAPE: {score:.2f}\")\n",
        "\n",
        "    avg_score = np.mean(smape_scores)\n",
        "    print(f\"\\nğŸ“Š Average Local CV SMAPE (n={n_splits} folds): {avg_score:.2f}\")\n",
        "    return smape_scores\n"
      ],
      "metadata": {
        "id": "rFp_4mNuFQHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Local CV\n",
        "time_series_local_cv(train_feat, feature_cols, n_splits=5, val_days=7)"
      ],
      "metadata": {
        "id": "cEnTocy5FV38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404fda17-2575-421f-d6ad-487448062a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 | Validation Date from 2024-06-09 â†’ SMAPE: 140.34\n",
            "Fold 2 | Validation Date from 2024-06-02 â†’ SMAPE: 132.85\n",
            "Fold 3 | Validation Date from 2024-05-26 â†’ SMAPE: 135.35\n",
            "Fold 4 | Validation Date from 2024-05-19 â†’ SMAPE: 129.40\n",
            "Fold 5 | Validation Date from 2024-05-12 â†’ SMAPE: 132.79\n",
            "\n",
            "ğŸ“Š Average Local CV SMAPE (n=5 folds): 134.15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(140.34055895783737),\n",
              " np.float64(132.85075417186223),\n",
              " np.float64(135.34844496133425),\n",
              " np.float64(129.4039144348293),\n",
              " np.float64(132.7859433018116)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ],
      "metadata": {
        "id": "E4c8pBKkG4Nh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "I2aoxBRCG5ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "4Hp7H3WzG7S8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "sHXYrHOyHEfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "WYIBpgo7G8m8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "FkI6JV21HdWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gagyeomkim"
      ],
      "metadata": {
        "id": "JvCVomTDZzVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KGY"
      ],
      "metadata": {
        "id": "5PvM_N-ALaVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: ì˜ˆì¸¡\n",
        "y_pred = model.predict(val_split[feature_cols])\n",
        "\n",
        "# ì„±ëŠ¥ í‰ê°€ (SMAPE ì‚¬ìš©)\n",
        "score = smape(val_split['sales_amount'], y_pred)\n",
        "print(f\"Validation SMAPE: {score:.2f}\")\n"
      ],
      "metadata": {
        "id": "i_vO5KGDLhcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd827d7f-3a4e-44b4-d815-5116a815340c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation SMAPE: 138.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_test_features(train_df, raw_test_df, lags=(1,7,14), roll_window=7):\n",
        "    # 1) ê³µí†µ ì „ì²˜ë¦¬(í•œê¸€â†’ì˜ë¬¸ ë¦¬ë„¤ì„, ìº˜ë¦°ë” íŒŒìƒ ë“±)\n",
        "    T = dataPreProcessing(raw_test_df).copy()\n",
        "\n",
        "    # 2) test 28ì¼ì— ì‹¤ì œ ë§¤ì¶œì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ëŒ€ì²´)\n",
        "    if 'sales_amount' not in T.columns:\n",
        "        T['sales_amount'] = 0.0\n",
        "\n",
        "    combo = T.sort_values(['market_menu','date_time'])\n",
        "    combo = add_ts_features(combo, lags=lags, roll_window=roll_window)\n",
        "    combo = add_days_since_last_sale(combo)\n",
        "\n",
        "    feat_test = combo[combo['date_time'].isin(T['date_time']) &\n",
        "                      (combo['market_menu'].isin(T['market_menu']))].copy()\n",
        "    return feat_test\n",
        "\n"
      ],
      "metadata": {
        "id": "Gt2fXCtYLnSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def block_cv_28to7(df_prepped, feature_cols, n_folds=5, ctx_days=28, horizon=7, gap=0):\n",
        "    \"\"\"\n",
        "    [ì»¨í…ìŠ¤íŠ¸ 28ì¼] â†’ [ë‹¤ìŒ 7ì¼]ì„ ëˆ„ìˆ˜ ì—†ì´ ìë™íšŒê·€ ë¡¤ì•„ì›ƒìœ¼ë¡œ ê²€ì¦\n",
        "    - ì»¨í…ìŠ¤íŠ¸ 28ì¼ë§Œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš© (train tail ì‚¬ìš© ê¸ˆì§€)\n",
        "    - ê²€ì¦ 7ì¼ì˜ ì‹¤ì œê°’ì€ í”¼ì²˜ ê³„ì‚°ì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (teacher forcing ê¸ˆì§€)\n",
        "    \"\"\"\n",
        "    df_prepped = df_prepped.sort_values(['market_menu','date_time']).copy()\n",
        "    uniq = np.array(sorted(df_prepped['date_time'].unique()))\n",
        "    scores = []\n",
        "\n",
        "    for i in range(1, n_folds+1):\n",
        "        need = ctx_days + horizon + gap\n",
        "        if len(uniq) < need * i:\n",
        "            break\n",
        "\n",
        "        s = uniq[-need * i]  # ì»¨í…ìŠ¤íŠ¸ ì‹œì‘ì¼\n",
        "        ctx_start, ctx_end = s, s + pd.Timedelta(days=ctx_days-1)\n",
        "        val_start = ctx_end + pd.Timedelta(days=1+gap)\n",
        "        val_end   = val_start + pd.Timedelta(days=horizon-1)\n",
        "\n",
        "        # -------------------------\n",
        "        # 1) í•™ìŠµ: ì»¨í…ìŠ¤íŠ¸ ì‹œì‘ ì´ì „ë§Œ\n",
        "        # -------------------------\n",
        "        train_part = df_prepped[df_prepped['date_time'] < ctx_start].copy()\n",
        "        tr_feat  = add_ts_features(train_part)\n",
        "        tr_feat  = add_days_since_last_sale(tr_feat)\n",
        "        tr_feat['sales_amount'] = pd.to_numeric(tr_feat['sales_amount'], errors='coerce').fillna(0).clip(lower=0)\n",
        "\n",
        "        model = XGBRegressor(\n",
        "            n_estimators=600, max_depth=6, learning_rate=0.05,\n",
        "            subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1\n",
        "        )\n",
        "        model.fit(tr_feat[feature_cols], tr_feat['sales_amount'])\n",
        "\n",
        "        # -------------------------\n",
        "        # 2) ì¶”ë¡ : ì»¨í…ìŠ¤íŠ¸ 28ì¼ë§Œ ì‚¬ìš©\n",
        "        # -------------------------\n",
        "        ctx_only = df_prepped[(df_prepped['date_time'] >= ctx_start) &\n",
        "                              (df_prepped['date_time'] <= ctx_end)].copy()\n",
        "\n",
        "        # ì»¨í…ìŠ¤íŠ¸ë¡œ í”¼ì²˜ ìƒì„±\n",
        "        combo = ctx_only.sort_values(['market_menu','date_time']).copy()\n",
        "        combo = add_ts_features(combo)\n",
        "        combo = add_days_since_last_sale(combo)\n",
        "\n",
        "        # ê²€ì¦ ì •ë‹µ(ë¹„êµìš©) â€” í”¼ì²˜ì—” ì‚¬ìš© ê¸ˆì§€\n",
        "        val_truth = df_prepped[(df_prepped['date_time'] >= val_start) &\n",
        "                               (df_prepped['date_time'] <= val_end)][['market_menu','date_time','sales_amount']].copy()\n",
        "\n",
        "        # ì˜ˆì¸¡í•  ë©”ë‰´ ì§‘í•©(ì»¨í…ìŠ¤íŠ¸âˆ©ê²€ì¦ êµì§‘í•©ì´ ì•ˆì „)\n",
        "        menus = sorted(set(combo['market_menu']) & set(val_truth['market_menu']))\n",
        "\n",
        "        preds = []\n",
        "        for h in range(horizon):\n",
        "            fut_date = val_start + pd.Timedelta(days=h)\n",
        "\n",
        "            # ë¯¸ë˜ í•˜ë£¨ í–‰ ìƒì„±(ë§¤ë‰´ë³„), ìº˜ë¦°ë”/ë„ë©”ì¸ íŒŒìƒ ë¶™ì´ê¸°\n",
        "            fut = pd.DataFrame({\n",
        "                'date_time': [fut_date]*len(menus),\n",
        "                'market_menu': menus,\n",
        "                'sales_amount': 0.0\n",
        "            })\n",
        "            fut = dataPreProcessing(fut)[[\n",
        "                'date_time','market_menu','sales_amount',\n",
        "                'weekend','holiday','vacation_season',\n",
        "                'usage_type_encoded','is_premium'\n",
        "            ]]\n",
        "\n",
        "            # ì»¨í…ìŠ¤íŠ¸ + ì§€ê¸ˆê¹Œì§€ì˜ ì˜ˆì¸¡ì„ ê°€ì§„ comboì— ì´ì–´ë¶™ì´ê³  í”¼ì²˜ ê°±ì‹ \n",
        "            combo = pd.concat([combo, fut], ignore_index=True, sort=False)\n",
        "            combo = combo.sort_values(['market_menu','date_time'])\n",
        "            combo = add_ts_features(combo)\n",
        "            combo = add_days_since_last_sale(combo)\n",
        "\n",
        "            mask = combo['date_time'].eq(fut_date)\n",
        "            Xf = (combo.loc[mask, feature_cols]\n",
        "                        .apply(pd.to_numeric, errors='coerce')\n",
        "                        .fillna(0).astype(float))\n",
        "            y_hat = model.predict(Xf).clip(0)\n",
        "\n",
        "            # ë‹¤ìŒ stepì„ ìœ„í•´ ì˜ˆì¸¡ê°’ì„ ê¸°ë¡(teacher forcing ë°©ì§€)\n",
        "            combo.loc[mask, 'sales_amount'] = y_hat\n",
        "\n",
        "            preds.append(pd.DataFrame({\n",
        "                'market_menu': combo.loc[mask, 'market_menu'].values,\n",
        "                'date_time': fut_date,\n",
        "                'pred': y_hat\n",
        "            }))\n",
        "\n",
        "        pred_df = pd.concat(preds, ignore_index=True)\n",
        "        merged = val_truth.merge(pred_df, on=['market_menu','date_time'], how='left')\n",
        "        merged['pred'] = merged['pred'].fillna(0.0)\n",
        "\n",
        "        s_score = smape(merged['sales_amount'].to_numpy(), merged['pred'].to_numpy())\n",
        "        print(f\"Fold{i}: ctx {ctx_start.date()}~{ctx_end.date()} â†’ val {val_start.date()}~{val_end.date()} | SMAPE {s_score:.4f}\")\n",
        "        scores.append(s_score)\n",
        "\n",
        "    if scores:\n",
        "        print(\"Avg SMAPE:\", np.mean(scores))\n",
        "    return scores\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-J8vqtcBUXLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def block_cv_28to7_2stage(\n",
        "    df_prepped, feature_cols, n_folds=5, ctx_days=28, horizon=7, gap=0,\n",
        "    tau_grid=(0.3, 0.4, 0.5, 0.6), default_tau=0.5,\n",
        "    calibrate=False,          # Platt calibration ì ìš© ì—¬ë¶€\n",
        "    use_soft=True,            # soft ê²Œì´íŒ…(p_pos**alpha) ì‚¬ìš© ì—¬ë¶€\n",
        "    alpha=0.35                # soft ê²Œì´íŒ… ì§€ìˆ˜\n",
        "):\n",
        "    \"\"\"\n",
        "    [ì»¨í…ìŠ¤íŠ¸ 28ì¼] â†’ [ë‹¤ìŒ 7ì¼] ìë™íšŒê·€ ë¡¤ì•„ì›ƒ CV (ëˆ„ìˆ˜ ì—†ìŒ).\n",
        "    - ì»¨í…ìŠ¤íŠ¸ 28ì¼ë§Œ ì…ë ¥ ì‚¬ìš© (train tail/ë¯¸ë˜ ì‹¤ì œê°’ ê¸ˆì§€)\n",
        "    - use_soft=Trueë©´ ìµœì¢… ìŠ¤ì½”ì–´ë„ soft ë°©ì‹ìœ¼ë¡œ ê³„ì‚°\n",
        "    \"\"\"\n",
        "    df_prepped = df_prepped.sort_values(['market_menu','date_time']).copy()\n",
        "    uniq = np.array(sorted(df_prepped['date_time'].unique()))\n",
        "    scores = []\n",
        "\n",
        "    for i in range(1, n_folds+1):\n",
        "        need = ctx_days + horizon + gap\n",
        "        if len(uniq) < need * i:\n",
        "            break\n",
        "\n",
        "        s = uniq[-need * i]\n",
        "        ctx_start, ctx_end = s, s + pd.Timedelta(days=ctx_days-1)\n",
        "        val_start = ctx_end + pd.Timedelta(days=1+gap)\n",
        "        val_end   = val_start + pd.Timedelta(days=horizon-1)\n",
        "\n",
        "        # -------------------------\n",
        "        # 1) í•™ìŠµ: ì»¨í…ìŠ¤íŠ¸ ì‹œì‘ ì´ì „ë§Œ\n",
        "        # -------------------------\n",
        "        train_part = df_prepped[df_prepped['date_time'] < ctx_start].copy()\n",
        "        tr_feat = add_ts_features(train_part)\n",
        "        tr_feat = add_days_since_last_sale(tr_feat)\n",
        "\n",
        "        y = (pd.to_numeric(tr_feat['sales_amount'], errors='coerce')\n",
        "               .fillna(0).clip(lower=0).to_numpy())\n",
        "        X_tr = (tr_feat[feature_cols]\n",
        "                .apply(pd.to_numeric, errors='coerce')\n",
        "                .fillna(0).astype(float))\n",
        "\n",
        "        # ë¶„ë¥˜ê¸°(base) â†’ (ì˜µì…˜) Platt ë³´ì • â†’ proba í•¨ìˆ˜\n",
        "        pos_rate = (y > 0).mean()\n",
        "        neg_pos  = (1 - pos_rate) / max(pos_rate, 1e-6)\n",
        "\n",
        "        clf_base = XGBClassifier(\n",
        "            n_estimators=500, max_depth=6, learning_rate=0.05,\n",
        "            subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1,\n",
        "            scale_pos_weight=neg_pos\n",
        "        )\n",
        "        clf_base.fit(X_tr, (y > 0).astype(int))\n",
        "\n",
        "        if calibrate:\n",
        "            cal = CalibratedClassifierCV(clf_base, method='sigmoid', cv=3)\n",
        "            cal.fit(X_tr, (y > 0).astype(int))\n",
        "            proba = lambda X: cal.predict_proba(\n",
        "                X.apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "            )[:, 1]\n",
        "        else:\n",
        "            proba = lambda X: clf_base.predict_proba(\n",
        "                X.apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "            )[:, 1]\n",
        "\n",
        "        # íšŒê·€ê¸°\n",
        "        w = 1.0 / (1.0 + y)\n",
        "        t = np.log1p(y)\n",
        "        reg = XGBRegressor(\n",
        "            n_estimators=800, max_depth=7, learning_rate=0.04,\n",
        "            subsample=0.8, colsample_bytree=0.9, random_state=42, n_jobs=-1\n",
        "        )\n",
        "        reg.fit(X_tr, t, sample_weight=w)\n",
        "\n",
        "        # -------------------------\n",
        "        # 2) ì¶”ë¡ : ì»¨í…ìŠ¤íŠ¸ 28ì¼ë§Œ ì‚¬ìš© (ì˜¤í† ë¦¬ê·¸ë ˆì‹œë¸Œ ë¡¤ì•„ì›ƒ)\n",
        "        # -------------------------\n",
        "        ctx_only = df_prepped[(df_prepped['date_time'] >= ctx_start) &\n",
        "                              (df_prepped['date_time'] <= ctx_end)].copy()\n",
        "\n",
        "        combo = ctx_only.sort_values(['market_menu','date_time']).copy()\n",
        "        combo = add_ts_features(combo)\n",
        "        combo = add_days_since_last_sale(combo)\n",
        "\n",
        "        val_truth = df_prepped[(df_prepped['date_time'] >= val_start) &\n",
        "                               (df_prepped['date_time'] <= val_end)][['market_menu','date_time','sales_amount']].copy()\n",
        "        menus = sorted(set(combo['market_menu']) & set(val_truth['market_menu']))\n",
        "\n",
        "        rows = []\n",
        "        for h in range(horizon):\n",
        "            fut_date = val_start + pd.Timedelta(days=h)\n",
        "\n",
        "            fut = pd.DataFrame({\n",
        "                'date_time': [fut_date]*len(menus),\n",
        "                'market_menu': menus,\n",
        "                'sales_amount': 0.0\n",
        "            })\n",
        "            fut = dataPreProcessing(fut)[[\n",
        "                'date_time','market_menu','sales_amount',\n",
        "                'weekend','holiday','vacation_season',\n",
        "                'usage_type_encoded','is_premium'\n",
        "            ]]\n",
        "\n",
        "            combo = pd.concat([combo, fut], ignore_index=True, sort=False)\n",
        "            combo = combo.sort_values(['market_menu','date_time'])\n",
        "            combo = add_ts_features(combo)\n",
        "            combo = add_days_since_last_sale(combo)\n",
        "\n",
        "            mask = combo['date_time'].eq(fut_date)\n",
        "            Xf = (combo.loc[mask, feature_cols]\n",
        "                        .apply(pd.to_numeric, errors='coerce')\n",
        "                        .fillna(0).astype(float))\n",
        "\n",
        "            p_pos = proba(Xf)\n",
        "            y_hat = np.expm1(reg.predict(Xf))\n",
        "            y_hat = np.nan_to_num(y_hat, nan=0.0, posinf=0.0, neginf=0.0).clip(0)\n",
        "\n",
        "            # ë¡¤ì•„ì›ƒìš© ê¸°ë¡ê°’\n",
        "            if use_soft:\n",
        "                y_for_next = (y_hat * np.power(p_pos, alpha)).clip(0)\n",
        "            else:\n",
        "                y_for_next = y_hat\n",
        "\n",
        "            combo.loc[mask, 'sales_amount'] = y_for_next\n",
        "\n",
        "            rows.append(pd.DataFrame({\n",
        "                'market_menu': combo.loc[mask, 'market_menu'].values,\n",
        "                'date_time': fut_date,\n",
        "                'p': p_pos,\n",
        "                'yhat': y_hat\n",
        "            }))\n",
        "\n",
        "        preds_df = pd.concat(rows, ignore_index=True)\n",
        "        merged = val_truth.merge(preds_df, on=['market_menu','date_time'], how='left')\n",
        "        merged['yhat'] = merged['yhat'].fillna(0.0)\n",
        "        merged['p']    = merged['p'].fillna(0.0)\n",
        "\n",
        "        # -------------------------\n",
        "        # 3) ìµœì¢… ì˜ˆì¸¡: soft vs hard\n",
        "        # -------------------------\n",
        "        if use_soft:\n",
        "            final_pred = (merged['yhat'].to_numpy() * np.power(merged['p'].to_numpy(), alpha)).clip(0)\n",
        "        else:\n",
        "            # hard: per-menu Ï„ íƒìƒ‰\n",
        "            best_tau = {}\n",
        "            for menu, g in merged.groupby('market_menu'):\n",
        "                y_true = g['sales_amount'].to_numpy()\n",
        "                p      = g['p'].to_numpy()\n",
        "                yhat   = g['yhat'].to_numpy()\n",
        "                best_s, best_t = 1e9, default_tau\n",
        "                for t_ in tau_grid:\n",
        "                    pred_ = np.where(p < t_, 0.0, yhat).clip(0)\n",
        "                    s_ = smape(y_true, pred_)\n",
        "                    if s_ < best_s:\n",
        "                        best_s, best_t = s_, t_\n",
        "                best_tau[menu] = best_t\n",
        "\n",
        "            taus = merged['market_menu'].map(best_tau).fillna(default_tau).to_numpy()\n",
        "            final_pred = np.where(merged['p'].to_numpy() < taus, 0.0, merged['yhat'].to_numpy()).clip(0)\n",
        "\n",
        "        s_score = smape(merged['sales_amount'].to_numpy(), final_pred)\n",
        "        print(f\"[2stage NL] Fold{i}: ctx {ctx_start.date()}~{ctx_end.date()} â†’ val {val_start.date()}~{val_end.date()} | SMAPE {s_score:.4f}\")\n",
        "        scores.append(s_score)\n",
        "\n",
        "    if scores:\n",
        "        print(\"Avg SMAPE (2-stage, no-leak):\", np.mean(scores))\n",
        "    return scores\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Al9WKfYSXOKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Block CV (28â†’7, gap=0) / 1-stage ===\")\n",
        "_ = block_cv_28to7(train_df, feature_cols, n_folds=5, ctx_days=28, horizon=7, gap=0)\n",
        "\n",
        "print(\"\\n=== Block CV (28â†’7, gap=0) / 2-stage ===\")\n",
        "_ = block_cv_28to7_2stage(train_df, feature_cols, n_folds=5, ctx_days=28, horizon=7, gap=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKbVfTJ2Ur__",
        "outputId": "c1df35fb-d9a0-41c8-9b52-764723f37d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Block CV (28â†’7, gap=0) / 1-stage ===\n",
            "Fold1: ctx 2024-05-12~2024-06-08 â†’ val 2024-06-09~2024-06-15 | SMAPE 110.9638\n",
            "Fold2: ctx 2024-04-07~2024-05-04 â†’ val 2024-05-05~2024-05-11 | SMAPE 135.8765\n",
            "Fold3: ctx 2024-03-03~2024-03-30 â†’ val 2024-03-31~2024-04-06 | SMAPE 123.2955\n",
            "Fold4: ctx 2024-01-28~2024-02-24 â†’ val 2024-02-25~2024-03-02 | SMAPE 129.9081\n",
            "Fold5: ctx 2023-12-24~2024-01-20 â†’ val 2024-01-21~2024-01-27 | SMAPE 124.5387\n",
            "Avg SMAPE: 124.91651477793069\n",
            "\n",
            "=== Block CV (28â†’7, gap=0) / 2-stage ===\n",
            "[2stage NL] Fold1: ctx 2024-05-12~2024-06-08 â†’ val 2024-06-09~2024-06-15 | SMAPE 128.0442\n",
            "[2stage NL] Fold2: ctx 2024-04-07~2024-05-04 â†’ val 2024-05-05~2024-05-11 | SMAPE 138.9935\n",
            "[2stage NL] Fold3: ctx 2024-03-03~2024-03-30 â†’ val 2024-03-31~2024-04-06 | SMAPE 141.2198\n",
            "[2stage NL] Fold4: ctx 2024-01-28~2024-02-24 â†’ val 2024-02-25~2024-03-02 | SMAPE 142.1096\n",
            "[2stage NL] Fold5: ctx 2023-12-24~2024-01-20 â†’ val 2024-01-21~2024-01-27 | SMAPE 145.6584\n",
            "Avg SMAPE (2-stage, no-leak): 139.20511671811693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forecast_next7_for_block(\n",
        "    train_df,\n",
        "    raw_test_df,\n",
        "    feature_cols,\n",
        "    clf,\n",
        "    reg,\n",
        "    tau_by_menu=None,          # hard ëª¨ë“œì—ì„œë§Œ ì‚¬ìš©\n",
        "    default_tau=0.35,          # hard ëª¨ë“œì˜ ê¸°ë³¸ Ï„ (offëŠ” <0), soft ëª¨ë“œì—ì„  ë¬´ì‹œ\n",
        "    block_id=\"TEST_XX\",\n",
        "    gate_mode=\"soft\",          # \"soft\"(ê¸°ë³¸) | \"hard\" | \"off\"\n",
        "    alpha=0.30,\n",
        "    prob_gamma=0.6,            # soft ê²Œì´íŒ… ì§€ìˆ˜: y_final = y_hat * p_pos**alpha\n",
        "    tau_floor_prob=0.0,       # p_posê°€ ì´ë³´ë‹¤ ì‘ìœ¼ë©´ floor ë¯¸ì ìš©\n",
        "    floor_ratio=0.12,          # floor = (ì»¨í…ìŠ¤íŠ¸ ì–‘ìˆ˜ í‰ê· )*floor_ratio\n",
        "    scale_clip=(0.8, 12.0),     # ì»¨í…ìŠ¤íŠ¸ ìŠ¤ì¼€ì¼ í´ë¦¬í•‘ ë²”ìœ„\n",
        "    apply_scale=True,\n",
        "    apply_floor=True\n",
        "):\n",
        "    \"\"\"\n",
        "    ë°˜í™˜: DataFrame[token, ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…, ë§¤ì¶œìˆ˜ëŸ‰]  (+1~+7ì¼)\n",
        "    ì „ì œ: dataPreProcessing, add_ts_features, add_days_since_last_saleê°€ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆìŒ.\n",
        "    \"\"\"\n",
        "\n",
        "    # 0) ì»¨í…ìŠ¤íŠ¸ 28ì¼ ì¤€ë¹„\n",
        "    T = dataPreProcessing(raw_test_df).copy()\n",
        "    if 'sales_amount' not in T.columns:\n",
        "        T['sales_amount'] = 0.0\n",
        "\n",
        "     # ì»¨í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ íŒŒìƒ\n",
        "    combo = T.sort_values(['market_menu','date_time']).copy()\n",
        "    combo = add_ts_features(combo)\n",
        "    combo = add_days_since_last_sale(combo)\n",
        "\n",
        "    preds = []\n",
        "    ctx_last = combo['date_time'].max()\n",
        "    ctx_start = ctx_last - pd.Timedelta(days=27)   # 28ì¼ ì°½\n",
        "    menus = T['market_menu'].drop_duplicates().tolist()\n",
        "\n",
        "    # 1) ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë³´ì •ëŸ‰ ê³„ì‚° (soft ëª¨ë“œìš©)\n",
        "    #    - ë©”ë‰´ë³„ floor(ì–‘ìˆ˜ í‰ê· *ratio)\n",
        "    #    - ìµœê·¼ 7ì¼ ì‹¤ì œí•©/ì˜ˆì¸¡í•© ë¹„ìœ¨ë¡œ scale\n",
        "    floor_map, scale_by_menu = {}, {}\n",
        "    if gate_mode == \"soft\":\n",
        "        # (A) floor\n",
        "        ctx_hist = combo[(combo['date_time'] >= ctx_start) & (combo['date_time'] <= ctx_last)].copy()\n",
        "        q = 0.45\n",
        "        pos_q = (ctx_hist[ctx_hist['sales_amount'] > 0]\n",
        "             .groupby('market_menu')['sales_amount']\n",
        "             .quantile(q).fillna(0.0))\n",
        "        floor_map = (floor_ratio * pos_q).to_dict() if apply_floor else {}\n",
        "\n",
        "        # (B) scale (ìµœê·¼ 7ì¼)\n",
        "        ctx7_mask = combo['date_time'].between(ctx_last - pd.Timedelta(days=6), ctx_last)\n",
        "        scale_by_menu = {}\n",
        "        if ctx7_mask.any():\n",
        "            X_ctx7 = (ctx_hist.loc[ctx7_mask, feature_cols]\n",
        "                  .apply(pd.to_numeric, errors='coerce').fillna(0).astype(float))\n",
        "            y_ctx7_hat = np.expm1(reg.predict(X_ctx7))\n",
        "            y_ctx7_hat = np.nan_to_num(y_ctx7_hat, nan=0.0, posinf=0.0, neginf=0.0).clip(0)\n",
        "\n",
        "            hat_sum_by_menu = pd.Series(y_ctx7_hat,\n",
        "                                    index=ctx_hist.loc[ctx7_mask, 'market_menu']).groupby(level=0).sum()\n",
        "            true_sum_by_menu = ctx_hist.loc[ctx7_mask].groupby('market_menu')['sales_amount'].sum()\n",
        "            scale_series = (true_sum_by_menu / (hat_sum_by_menu + 1e-6)).fillna(1.0)\n",
        "            global_scale = float(true_sum_by_menu.sum() / (hat_sum_by_menu.sum() + 1e-6))\n",
        "            scale_series = 0.5*scale_series + 0.5*global_scale\n",
        "            if apply_scale:\n",
        "                scale_series = scale_series.clip(lower=0.8, upper=12.0)\n",
        "                scale_by_menu = scale_series.to_dict()\n",
        "            else:\n",
        "                scale_by_menu = {k: 1.0 for k in true_sum_by_menu.index}\n",
        "\n",
        "    # 2) 7-step ë¡¤ì•„ì›ƒ\n",
        "    for h in range(1, 8):\n",
        "        fut_date = ctx_last + pd.Timedelta(days=h)\n",
        "        # ë¯¸ë˜ í•œ ì¤„(ê° ë©”ë‰´) ìƒì„± + ê³µí†µ íŒŒìƒ\n",
        "        fut = pd.DataFrame({\n",
        "            'date_time': [fut_date]*len(menus),\n",
        "            'market_menu': menus,\n",
        "            'sales_amount': 0.0\n",
        "        })\n",
        "        fut = dataPreProcessing(fut)[[\n",
        "            'date_time','market_menu','sales_amount',\n",
        "            'weekend','holiday','vacation_season',\n",
        "            'usage_type_encoded','is_premium','store_name','menu_name'\n",
        "        ]]\n",
        "\n",
        "        # ì»¨í…Œì´ë„ˆì— ë¶™ì—¬ ë™ì¼ í”¼ì²˜ ìƒì„±\n",
        "        combo = pd.concat([combo, fut], ignore_index=True, sort=False)\n",
        "        combo = combo.sort_values(['market_menu','date_time'])\n",
        "        combo = add_ts_features(combo)\n",
        "        combo = add_days_since_last_sale(combo)\n",
        "\n",
        "        # ë°©ê¸ˆ ì¶”ê°€í•œ ë¯¸ë˜í–‰ë§Œ ì˜ˆì¸¡\n",
        "        mask = (combo['date_time'] == fut_date)\n",
        "        Xf = combo.loc[mask, feature_cols].copy()\n",
        "        Xf = Xf.apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "\n",
        "        p_pos = clf.predict_proba(Xf)[:, 1]\n",
        "        # ì„ íƒ: í™•ë¥  íŒ½ì°½(ì‘ì„ìˆ˜ë¡ ëœ ê¹ì´ê²Œ í•¨)\n",
        "        if prob_gamma is not None and prob_gamma != 1.0:\n",
        "            p_pos = 1.0 - np.power(1.0 - p_pos, prob_gamma)\n",
        "        y_hat = np.expm1(reg.predict(Xf))\n",
        "        y_hat = np.nan_to_num(y_hat, nan=0.0, posinf=0.0, neginf=0.0).clip(0)\n",
        "\n",
        "        if gate_mode == \"off\" or (default_tau is not None and default_tau < 0):\n",
        "            # ê²Œì´íŒ… ì™„ì „ OFF\n",
        "            y_final = y_hat.copy()\n",
        "\n",
        "        elif gate_mode == \"hard\":\n",
        "            # í•˜ë“œ ê²Œì´íŒ… (ê¸°ì¡´ ë°©ì‹ ìœ ì§€ ì˜µì…˜)\n",
        "            if tau_by_menu is None:\n",
        "                tau_vec = np.full(len(Xf), (default_tau if default_tau is not None else 0.35))\n",
        "            else:\n",
        "                tau_vec = np.array([\n",
        "                    tau_by_menu.get(m, (default_tau if default_tau is not None else 0.35))\n",
        "                    for m in combo.loc[mask, 'market_menu']\n",
        "                ])\n",
        "            y_final = np.where(p_pos < tau_vec, 0.0, y_hat).clip(0)\n",
        "\n",
        "        else:\n",
        "            # SOFT ê²Œì´íŒ… + ìŠ¤ì¼€ì¼ + ë°”ë‹¥ê°’\n",
        "            # 1) ì†Œí”„íŠ¸ ê²Œì´íŒ…\n",
        "            y_soft = y_hat * np.power(p_pos, (alpha if alpha is not None else 0.0))\n",
        "\n",
        "            # 2) ë©”ë‰´ë³„ ìŠ¤ì¼€ì¼\n",
        "            if apply_scale and len(scale_by_menu):\n",
        "                s_vec = np.array([scale_by_menu.get(m, 1.0) for m in combo.loc[mask, 'market_menu']])\n",
        "                y_scaled = (y_soft * s_vec).clip(0)\n",
        "            else:\n",
        "                y_scaled = y_soft\n",
        "\n",
        "            # 3) ë°”ë‹¥ê°’ (í™•ë¥ ì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ floor ë¯¸ì ìš©)\n",
        "            if apply_floor and len(floor_map):\n",
        "                floor_vec = np.array([floor_map.get(m, 0.0) for m in combo.loc[mask, 'market_menu']])\n",
        "                apply_mask = p_pos >= (tau_floor_prob if tau_floor_prob is not None else 0.0)\n",
        "                # p_posê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ floor ë¯¸ì ìš© â†’ ê·¸ëŒ€ë¡œ y_scaled\n",
        "                y_final = np.where(apply_mask, np.maximum(y_scaled, floor_vec), y_scaled).clip(0)\n",
        "            else:\n",
        "                y_final = y_scaled\n",
        "\n",
        "        ctx_hist = combo[combo['date_time'] <= ctx_last].copy()  # ì»¨í…ìŠ¤íŠ¸ 28ì¼ê¹Œì§€ë§Œ\n",
        "        dow = fut_date.dayofweek\n",
        "        true_day_sums = (\n",
        "            ctx_hist.assign(dow=ctx_hist['date_time'].dt.dayofweek)\n",
        "                    .query('dow == @dow')\n",
        "                    .groupby('date_time')['sales_amount'].sum()\n",
        "        )\n",
        "        if len(true_day_sums):\n",
        "            target_sum = float(true_day_sums.median())  # í•„ìš”ì‹œ mean()ìœ¼ë¡œ êµì²´ ê°€ëŠ¥\n",
        "            pred_sum = float(y_final.sum()) + 1e-6\n",
        "            k = np.clip(target_sum / pred_sum, 0.5, 8.0)  # ê³¼ë„ ì™œê³¡ ë°©ì§€\n",
        "            y_final = (y_final * k).clip(0)\n",
        "\n",
        "        # ë‹¤ìŒ stepì˜ ë¼ê·¸/ë¡¤ë§ ë°˜ì˜ì„ ìœ„í•´ ì˜ˆì¸¡ê°’ì„ comboì— ê¸°ë¡\n",
        "        combo.loc[mask, 'sales_amount'] = y_final\n",
        "\n",
        "        # ê²°ê³¼ ì €ì¥\n",
        "        preds.append(pd.DataFrame({\n",
        "            'token': [f\"{block_id}+{h}ì¼\"] * np.sum(mask),\n",
        "            'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': combo.loc[mask, 'market_menu'].values,\n",
        "            'ë§¤ì¶œìˆ˜ëŸ‰': y_final\n",
        "        }))\n",
        "\n",
        "    return pd.concat(preds, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "TBRNbiaaxRK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì „ì²´ trainìœ¼ë¡œ ìµœì¢… í•™ìŠµ\n",
        "tr_feat_full = add_ts_features(train_df)\n",
        "tr_feat_full = add_days_since_last_sale(tr_feat_full)\n",
        "# X/y ì •ë¦¬ (ìˆ«ìí˜• ê°•ì œ)\n",
        "Xf_full = tr_feat_full[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "y_full  = (pd.to_numeric(tr_feat_full['sales_amount'], errors='coerce')\n",
        "           .fillna(0).clip(lower=0).to_numpy())\n",
        "\n",
        "# ë¶„ë¥˜ê¸° (ë¶ˆê· í˜• ë³´ì •)\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "pos_rate = (y_full > 0).mean()\n",
        "neg_pos  = (1 - pos_rate) / max(pos_rate, 1e-6)\n",
        "\n",
        "clf = XGBClassifier(\n",
        "    n_estimators=600, max_depth=6, learning_rate=0.05,\n",
        "    subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1,\n",
        "    scale_pos_weight=neg_pos\n",
        ")\n",
        "clf.fit(Xf_full, (y_full > 0).astype(int))\n",
        "\n",
        "# íšŒê·€ê¸° (log1p + ê°€ì¤‘ì¹˜)\n",
        "w_full = 1.0 / (1.0 + y_full)\n",
        "reg = XGBRegressor(\n",
        "    n_estimators=900, max_depth=7, learning_rate=0.04,\n",
        "    subsample=0.8, colsample_bytree=0.9, random_state=42, n_jobs=-1\n",
        ")\n",
        "reg.fit(Xf_full, np.log1p(y_full), sample_weight=w_full)\n"
      ],
      "metadata": {
        "id": "3m2p9EmacaSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_tau_by_menu_last_block(train_df, feature_cols, tau_grid=np.arange(0.25, 0.76, 0.05)):\n",
        "    # ë§ˆì§€ë§‰ ì»¨í…ìŠ¤íŠ¸ 28ì¼ â†’ ë‹¤ìŒ 7ì¼ì„ ê²€ì¦ìœ¼ë¡œ ì‚¬ìš©\n",
        "    df = train_df.sort_values(['market_menu','date_time']).copy()\n",
        "    uniq = np.array(sorted(df['date_time'].unique()))\n",
        "    ctx_days, horizon = 28, 7\n",
        "    s = uniq[-(ctx_days + horizon)]\n",
        "    ctx_start, ctx_end = s, s + pd.Timedelta(days=ctx_days-1)\n",
        "    val_start = ctx_end + pd.Timedelta(days=1)\n",
        "    val_end   = val_start + pd.Timedelta(days=horizon-1)\n",
        "\n",
        "    train_part = df[df['date_time'] < ctx_start].copy()\n",
        "    tail = train_part.groupby('market_menu', as_index=False).tail(max(28,14,7))\n",
        "    combo = pd.concat([\n",
        "        tail,\n",
        "        df[(df['date_time']>=ctx_start) & (df['date_time']<=ctx_end)],\n",
        "        df[(df['date_time']>=val_start) & (df['date_time']<=val_end)],\n",
        "    ], ignore_index=True, sort=False).sort_values(['market_menu','date_time'])\n",
        "\n",
        "    # í•™ìŠµ\n",
        "    tr_feat = add_ts_features(train_part); tr_feat = add_days_since_last_sale(tr_feat)\n",
        "    X_tr = tr_feat[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "    y    = (pd.to_numeric(tr_feat['sales_amount'], errors='coerce').fillna(0).clip(lower=0).to_numpy())\n",
        "\n",
        "    pos_rate = (y > 0).mean(); neg_pos = (1 - pos_rate) / max(pos_rate, 1e-6)\n",
        "    clf = XGBClassifier(n_estimators=600, max_depth=6, learning_rate=0.05,\n",
        "                        subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1,\n",
        "                        scale_pos_weight=neg_pos)\n",
        "    clf.fit(X_tr, (y>0).astype(int))\n",
        "\n",
        "    w = 1.0/(1.0+y); t = np.log1p(y)\n",
        "    reg = XGBRegressor(n_estimators=900, max_depth=7, learning_rate=0.04,\n",
        "                       subsample=0.8, colsample_bytree=0.9, random_state=42, n_jobs=-1)\n",
        "    reg.fit(X_tr, t, sample_weight=w)\n",
        "\n",
        "    # ê²€ì¦ ë¸”ë¡\n",
        "    combo_ft = add_ts_features(combo); combo_ft = add_days_since_last_sale(combo_ft)\n",
        "    val_block = combo_ft[(combo_ft['date_time']>=val_start)&(combo_ft['date_time']<=val_end)].copy()\n",
        "    X_val = val_block[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "    p_pos = clf.predict_proba(X_val)[:,1]\n",
        "    y_hat = np.expm1(reg.predict(X_val)); y_hat = np.nan_to_num(y_hat, nan=0.0, posinf=0.0, neginf=0.0).clip(0)\n",
        "\n",
        "    # ë©”ë‰´ë³„ Ï„ ê³ ë¥´ê¸°\n",
        "    tau_map = {}\n",
        "    tmp = val_block.assign(p=p_pos, yhat=y_hat)\n",
        "    for menu, g in tmp.groupby('market_menu'):\n",
        "        best_s, best_t = 1e9, 0.5\n",
        "        for t_ in tau_grid:\n",
        "            pred_ = np.where(g['p'].to_numpy() < t_, 0.0, g['yhat'].to_numpy()).clip(0)\n",
        "            s_ = smape(g['sales_amount'].to_numpy(), pred_)\n",
        "            if s_ < best_s:\n",
        "                best_s, best_t = s_, t_\n",
        "        tau_map[menu] = best_t\n",
        "    return tau_map\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w89hCVQF3GTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b4357a-4452-4d4b-dfeb-615077a00f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ï„ keys: 1351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tau_by_menu = pick_tau_by_menu_last_block(train_df, feature_cols)\n",
        "print(\"ë©”ë‰´ë³„ Ï„ ê°œìˆ˜:\", len(tau_by_menu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp6zx6Ku3Hx3",
        "outputId": "8338d0e2-a3a4-4f75-da85-bd22bcd772b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë©”ë‰´ë³„ Ï„ ê°œìˆ˜: 1351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "Jshgqe-EG-P7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "D0EhDF9THmWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KGY VERSION"
      ],
      "metadata": {
        "id": "9B4l-JdeMZfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# A. ë¸”ë¡ë³„ ì˜ˆì¸¡ â†’ full_pred_df (ì¤‘ë³µ ì—†ì´ í•˜ë‚˜ë¡œ)\n",
        "# ------------------------------------------------------\n",
        "def infer_all_blocks(test_glob_pattern,\n",
        "                     train_df, feature_cols, clf, reg,\n",
        "                     gate_kwargs):\n",
        "    \"\"\"\n",
        "    test_glob_pattern: './test/TEST_*.csv'\n",
        "    gate_kwargs: forecast_next7_for_blockì— ë°”ë¡œ ì „ë‹¬í•  ê²Œì´íŒ…/ìŠ¤ì¼€ì¼ kwargs\n",
        "                 (ì˜ˆ: {'gate_mode':'soft', 'alpha':0.5, ...})\n",
        "    ë°˜í™˜: full_pred_df (token, ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…, ë§¤ì¶œìˆ˜ëŸ‰ í¬í•¨)\n",
        "    \"\"\"\n",
        "    test_files = sorted(glob.glob(test_glob_pattern))\n",
        "    all_preds = []\n",
        "\n",
        "    # tau_by_menuê°€ ìˆìœ¼ë©´ ìë™ ì²¨ë¶€ (ìˆì„ ë•Œë§Œ)\n",
        "    if 'tau_by_menu' not in gate_kwargs:\n",
        "        try:\n",
        "            gate_kwargs = {**gate_kwargs, 'tau_by_menu': tau_by_menu}\n",
        "        except NameError:\n",
        "            pass  # ì‚¬ìš© ì•ˆ í•¨\n",
        "\n",
        "    for path in test_files:\n",
        "        raw_test = pd.read_csv(path)\n",
        "        block_id = os.path.splitext(os.path.basename(path))[0]  # e.g., TEST_00\n",
        "\n",
        "        pred7 = forecast_next7_for_block(\n",
        "            train_df=train_df,\n",
        "            raw_test_df=raw_test,\n",
        "            feature_cols=feature_cols,\n",
        "            clf=clf, reg=reg,\n",
        "            block_id=block_id,\n",
        "            **gate_kwargs\n",
        "        )\n",
        "        all_preds.append(pred7)\n",
        "\n",
        "    full_pred_df = pd.concat(all_preds, ignore_index=True)\n",
        "    return full_pred_df\n",
        "\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# B. full_pred_df â†’ ì œì¶œ DF (ë²¡í„°í™”, ì¡°ê°í™” ê²½ê³  ì—†ìŒ)\n",
        "# ------------------------------------------------------\n",
        "def build_submission(full_pred_df, sample_submission_path, save_path=None):\n",
        "    sample_submission = pd.read_csv(sample_submission_path)\n",
        "    sub_tokens = sample_submission['ì˜ì—…ì¼ì'].astype(str)\n",
        "    menu_cols = [c for c in sample_submission.columns if c != 'ì˜ì—…ì¼ì']\n",
        "\n",
        "    # dedup + pivot_table\n",
        "    dedup = (full_pred_df\n",
        "             .groupby(['token','ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'], as_index=False)['ë§¤ì¶œìˆ˜ëŸ‰']\n",
        "             .sum())\n",
        "    wide_pred = dedup.pivot_table(index='token',\n",
        "                                  columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…',\n",
        "                                  values='ë§¤ì¶œìˆ˜ëŸ‰',\n",
        "                                  aggfunc='sum',\n",
        "                                  fill_value=0.0)\n",
        "\n",
        "    # ìˆœì„œ/ì»¬ëŸ¼ ë§ì¶° í•œ ë²ˆì— ìƒì„±(ì¡°ê°í™” ê²½ê³  X)\n",
        "    arr = (wide_pred\n",
        "           .reindex(index=sub_tokens, columns=menu_cols, fill_value=0.0)\n",
        "           .astype('float64'))\n",
        "    sub_out = arr.reset_index().rename(columns={'token':'ì˜ì—…ì¼ì'})\n",
        "\n",
        "    vals = sub_out[menu_cols].to_numpy(dtype='float64')\n",
        "    print(\"[SUB] sum:\", float(np.nansum(vals)))\n",
        "    print(\"[SUB] nonzero:\", int(np.count_nonzero(vals)))\n",
        "    print(\"[SUB] zero_ratio:\", float((vals == 0).mean()))\n",
        "\n",
        "    if save_path is not None:\n",
        "        os.makedirs(os.path.dirname(save_path) or '.', exist_ok=True)\n",
        "        sub_out.to_csv(save_path, index=False, encoding='utf-8-sig', float_format='%.6f')\n",
        "        print(\"ğŸ’¾ Saved:\", save_path)\n",
        "\n",
        "    return sub_out, wide_pred\n",
        "\n",
        "# ======================================================\n",
        "# ì‚¬ìš© ì˜ˆì‹œ\n",
        "#   1) OFFë¡œ ìŠ¤ëª¨í¬ ì²´í¬ (ì›ì¸ ë¶„ë¦¬)\n",
        "#   2) ONìœ¼ë¡œ ìµœì¢… ì œì¶œ ìƒì„±\n",
        "# ======================================================\n",
        "\n",
        "# 1) ê²Œì´íŒ… OFF (ì§„ì§œ off)\n",
        "RUN_OFF_CHECK = True\n",
        "if RUN_OFF_CHECK:\n",
        "    gate_off = dict(gate_mode='off',\n",
        "                    alpha=0.5,                 # offì—ì„œëŠ” ë¬´ì‹œë¨\n",
        "                    tau_floor_prob=0.0,        # ë¬´ì‹œë¨\n",
        "                    floor_ratio=0.10,          # ë¬´ì‹œë¨\n",
        "                    scale_clip=(0.5, 6.0),     # ë¬´ì‹œë¨\n",
        "                    apply_scale=True,\n",
        "                    apply_floor=True)\n",
        "    full_off = infer_all_blocks('./test/TEST_*.csv',\n",
        "                                train_df, feature_cols, clf, reg,\n",
        "                                gate_off)\n",
        "    sub_off, wide_off = build_submission(full_off,\n",
        "                                         './sample_submission.csv',\n",
        "                                         './submission/xgb_off.csv')\n",
        "\n",
        "# 2) ê²Œì´íŒ… ON (ì†Œí”„íŠ¸ ê²Œì´íŒ… ì¶”ì²œ)\n",
        "gate_on = dict(gate_mode='soft',\n",
        "               alpha=0.30,            # 0.5~0.8 íŠœë‹\n",
        "               tau_floor_prob=0.00,  # floor í•­ìƒ í—ˆìš©(ê°’ ì¶•ì†Œ ë°©ì§€)\n",
        "               floor_ratio=0.15,     # 0.10~0.20 íŠœë‹\n",
        "               scale_clip=(0.8, 12.0),\n",
        "               prob_gamma=0.60,\n",
        "               apply_scale=True,\n",
        "               apply_floor=True)\n",
        "\n",
        "# ì˜ˆì¸¡ í›„\n",
        "full_pred_df = infer_all_blocks('./test/TEST_*.csv',\n",
        "                                train_df, feature_cols, clf, reg,\n",
        "                                gate_on)  # í˜¹ì€ gate_off\n",
        "\n",
        "sub_out, wide_pred = build_submission(full_pred_df, './sample_submission.csv')\n",
        "\n",
        "# â¬‡ï¸ ë„¤ê°€ ì“°ë˜ ì €ì¥ ìŠ¤íƒ€ì¼ ê·¸ëŒ€ë¡œ\n",
        "os.makedirs('./submission', exist_ok=True)\n",
        "out_path = './submission/xgb_submission.csv'\n",
        "sub_out.to_csv(out_path, index=False, encoding='utf-8-sig', float_format='%.6f')\n",
        "print(\"âœ… ì €ì¥ ì™„ë£Œ â†’\", out_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar0WlvllGUXb",
        "outputId": "26bc44d8-eecf-418d-e697-27b0ca25210d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUB] sum: 24270.699296848597\n",
            "[SUB] nonzero: 13510\n",
            "[SUB] zero_ratio: 0.0\n",
            "[SUB] day total min/mean/max: 200.22442292556866 346.72427566926564 615.6228600000005\n",
            "ğŸ’¾ Saved: ./submission/xgb_off.csv\n",
            "[SUB] sum: 38377.58721184859\n",
            "[SUB] nonzero: 13510\n",
            "[SUB] zero_ratio: 0.0\n",
            "[SUB] day total min/mean/max: 256.84000000000003 548.2512458835512 1128.44\n",
            "ğŸ’¾ Saved: ./submission/xgb_submission.csv\n",
            "âœ… ì €ì¥ ì™„ë£Œ â†’ ./submission/xgb_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì œì¶œ ë¹Œë“œ ë’¤\n",
        "vals = sub_out.iloc[:,1:].to_numpy(dtype='float64')\n",
        "print(\"sum:\", float(np.nansum(vals)))\n",
        "print(\"nonzero:\", int(np.count_nonzero(vals)))\n",
        "print(\"zero_ratio:\", float((vals == 0).mean()))\n",
        "\n",
        "totals = sub_out.iloc[:,1:].sum(axis=1)\n",
        "print(\"day total min/mean/max:\", totals.min(), totals.mean(), totals.max())\n",
        "print(sub_out.iloc[:,1:].sum(axis=0).sort_values(ascending=False).head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17dzCgZLLDkA",
        "outputId": "6b79f4d3-eb45-4c17-f62a-41b0097f4d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sum: 39481.21865\n",
            "nonzero: 10248\n",
            "zero_ratio: 0.24145077720207253\n",
            "day total min/mean/max: 130.8875 564.0174092857144 1265.1630500000012\n",
            "ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…\n",
            "í™”ë‹´ìˆ²ì£¼ë§‰_í•´ë¬¼íŒŒì „            2805.671963\n",
            "í¬ë ˆìŠ¤íŠ¸ë¦¿_ê¼¬ì¹˜ì–´ë¬µ            1798.250575\n",
            "ì¹´í˜í…Œë¦¬ì•„_ë‹¨ì²´ì‹ 18000(ì‹ )    1515.085000\n",
            "ë¯¸ë¼ì‹œì•„_ë¸ŒëŸ°ì¹˜(ëŒ€ì¸) ì£¼ë§       1198.400000\n",
            "ì¹´í˜í…Œë¦¬ì•„_ë‹¨ì²´ì‹ 13000(ì‹ )    1136.113950\n",
            "ì—°íšŒì¥_Regular Coffee    1096.049225\n",
            "í¬ë ˆìŠ¤íŠ¸ë¦¿_ë–¡ë³¶ì´             1095.447700\n",
            "í¬ë ˆìŠ¤íŠ¸ë¦¿_ìƒìˆ˜              1070.093575\n",
            "í™”ë‹´ìˆ²ì¹´í˜_ì•„ë©”ë¦¬ì¹´ë…¸ ICE        810.083588\n",
            "ì¹´í˜í…Œë¦¬ì•„_ìˆ˜ì œ ë“±ì‹¬ ëˆê¹ŒìŠ¤        797.683837\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}