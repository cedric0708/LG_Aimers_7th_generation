{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FkI6JV21HdWy"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "Btjy4-h5Gp8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Files"
      ],
      "metadata": {
        "id": "06nQT4xN4Yw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE4yAQHe5jnU",
        "outputId": "36a11ba9-814e-4023-d4c5-bb34a2cc2a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import os\n",
        "\n",
        "file_id = '1_Xo2vU82JSSadBdD1Kb7iImHnEYdoFGh'\n",
        "output = 'open.zip' # 저장할 파일 이름\n",
        "\n",
        "# 'output'으로 지정된 파일이 현재 경로에 존재하지 않을 경우에만 다운로드 실행\n",
        "if not os.path.exists(output):\n",
        "    print(f\"'{output}' 파일이 없어 다운로드를 시작합니다.\")\n",
        "    gdown.download(id=file_id, output=output)\n",
        "else:\n",
        "    print(f\"'{output}' 파일이 이미 존재합니다. 다운로드를 건너뜁니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrY5NWym633Z",
        "outputId": "e436dfbd-e9f7-44cc-c543-e5dca10859f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'open.zip' 파일이 이미 존재합니다. 다운로드를 건너뜁니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -qq '/파일 경로/파일명.zip' -d '저장할 dir 위치 경로'\n",
        "!unzip -qq '/content/open.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "bn7qrkQ29SJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a7fafa-d2a0-4ba5-8127-8e8616f947a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "SZuHPwZHGsCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60myyOqfGNYD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import glob\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import holidays\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixed RandomSeed & Setting Hyperparameter"
      ],
      "metadata": {
        "id": "Z_dVtm98Gu2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "WykYlxUmGvqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)    # 1. 파이썬 내장 random 라이브러리의 시드를 고정합니다.\n",
        "    np.random.seed(seed)    # 2. NumPy 라이브러리의 난수 생성 시드를 고정합니다.\n",
        "    torch.manual_seed(seed)    # 3. PyTorch의 CPU 연산에 대한 난수 생성 시드를 고정합니다.\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)    # 4. 파이썬의 해시 시드를 고정하여 딕셔너리 등의 순서를 보장합니다.\n",
        "\n",
        "    # 5. CUDA (GPU) 사용이 가능한 경우, GPU 관련 시드 및 설정을 고정합니다.\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)    # 5-1. 현재 사용 중인 GPU의 난수 생성 시드를 고정합니다.\n",
        "        torch.cuda.manual_seed_all(seed)    # 5-2. 여러 개의 GPU를 사용하는 경우, 모든 GPU의 시드를 고정합니다.\n",
        "        torch.backends.cudnn.deterministic = True   # 5-3. cuDNN 라이브러리가 항상 결정적인(deterministic) 알고리즘만 사용하도록 설정합니다.\n",
        "        torch.backends.cudnn.benchmark = False  # 5-4. cuDNN의 벤치마크 기능을 비활성화합니다.\n",
        "\n",
        "set_seed(42)    # 위에서 정의한 함수를 seed 값 42로 실행하여 코드 전체의 재현성을 확보합니다."
      ],
      "metadata": {
        "id": "dbE2YGZJGvXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "LOOKBACK=28: 과거 28일치 데이터를 보고\n",
        "PREDICT=7: 미래 7일치를 에측\n",
        "BATCH_SIZE=16: 한번에 16개의 data를 묶어 학습\n",
        "EPOCHS=50: 전체 데이터를 50번 반복학습\n",
        "\"\"\"\n",
        "LOOKBACK, PREDICT, BATCH_SIZE, EPOCHS = 28, 7, 16, 50\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "YjZTezKNGzdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "awCUrimaG05S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('./train/train.csv')"
      ],
      "metadata": {
        "id": "HyvYhNW4G2Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import holidays\n",
        "\n",
        "def dataPreProcessing(df):\n",
        "    # 1. 열 이름 정리\n",
        "    df = df.rename(columns={\n",
        "        '영업일자': 'date_time',\n",
        "        '영업장명_메뉴명': 'market_menu',\n",
        "        '매출수량': 'sales_amount'\n",
        "    }) if '영업일자' in df.columns else df\n",
        "\n",
        "    # 2. 날짜 파생\n",
        "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
        "    df['weekday'] = df['date_time'].dt.weekday\n",
        "    df['weekend'] = df['weekday'].isin([5, 6]).astype(int)\n",
        "    df['month'] = df['date_time'].dt.month\n",
        "    df['dayofweek'] = df['date_time'].dt.dayofweek\n",
        "    df['day'] = df['date_time'].dt.day\n",
        "\n",
        "    # 3. 공휴일\n",
        "    kr_holidays = holidays.KR()\n",
        "    df['holiday'] = df['date_time'].dt.date.apply(lambda d: int(d in kr_holidays))\n",
        "\n",
        "    # 4. 방학 시즌 (1,2,7,8월)\n",
        "    df['vacation_season'] = df['month'].isin([1, 2, 7, 8]).astype(int)\n",
        "\n",
        "    # 5. 메뉴명 분해\n",
        "    df[['store_name', 'menu_name']] = df['market_menu'].str.split('_', n=1, expand=True)\n",
        "\n",
        "    # 6. 사용유형 추정\n",
        "    def classify_usage_type(menu):\n",
        "        if pd.isna(menu): return '기타'\n",
        "        if '어린이' in menu: return '어린이'\n",
        "        elif re.search(r'단체|플래터|무제한|[3-9]인|인분|세트', str(menu)): return '단체'\n",
        "        elif '2인' in menu: return '커플'\n",
        "        elif '1인' in menu or '단품' in menu or 'Gls' in menu: return '1인'\n",
        "        else: return '일반'\n",
        "\n",
        "    df['usage_type'] = df['menu_name'].apply(classify_usage_type)\n",
        "\n",
        "    # 7. 고급 메뉴 여부\n",
        "    df['is_premium'] = df['menu_name'].str.contains('한우|프리미엄|수제|특선|와인').fillna(False).astype(int)\n",
        "\n",
        "    # 10. 라벨 인코딩 (사용유형)\n",
        "    usage_map = {'1인': 0, '커플': 1, '단체': 2, '어린이': 3, '일반': 4, '기타': 5}\n",
        "    df['usage_type_encoded'] = df['usage_type'].map(usage_map).fillna(5).astype(int)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "dP_9M_w8TaD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로 추가: 그룹별 시계열 피처\n",
        "def add_ts_features(df, lags=(1,7,14), roll_window=7):\n",
        "    df = df.sort_values(['market_menu','date_time']).copy()\n",
        "    g = df.groupby('market_menu')['sales_amount']\n",
        "\n",
        "    for lag in lags:\n",
        "        df[f'lag_{lag}'] = g.shift(lag)\n",
        "\n",
        "    def _rmean(s): return s.shift(1).rolling(roll_window, min_periods=1).mean()\n",
        "    def _rstd(s):  return s.shift(1).rolling(roll_window, min_periods=1).std()\n",
        "\n",
        "    df['rolling_mean_7'] = df.groupby('market_menu')['sales_amount'].apply(_rmean).reset_index(level=0, drop=True)\n",
        "    df['rolling_std_7']  = df.groupby('market_menu')['sales_amount'].apply(_rstd).reset_index(level=0, drop=True)\n",
        "\n",
        "    # 수치 결측 안전 처리만 최소로\n",
        "    num_cols = [c for c in df.columns if df[c].dtype.kind in 'if']\n",
        "    df[num_cols] = df[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    return df"
      ],
      "metadata": {
        "id": "68DSHmmm85ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def smape(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true, dtype=float)\n",
        "    y_pred = np.asarray(y_pred, dtype=float)\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    out = np.zeros_like(denom)\n",
        "    mask = denom > 0\n",
        "    out[mask] = np.abs(y_true[mask] - y_pred[mask]) / denom[mask]\n",
        "    return out.mean() * 100.0\n",
        "\n",
        "def add_days_since_last_sale(df):\n",
        "    # 정렬 & 라벨 안전화\n",
        "    df = df.sort_values(['market_menu','date_time']).copy()\n",
        "    df['sales_amount'] = pd.to_numeric(df['sales_amount'], errors='coerce').fillna(0).clip(lower=0)\n",
        "\n",
        "    # 그룹별 '마지막 양수 판매일'을 forward-fill로 계산\n",
        "    pos_date = df['date_time'].where(df['sales_amount'] > 0)\n",
        "    df['last_pos_date'] = pos_date.groupby(df['market_menu']).ffill()\n",
        "\n",
        "    # 일수 계산(벡터화): pandas Timedelta → .dt.days 사용\n",
        "    delta = df['date_time'] - df['last_pos_date']\n",
        "    df['days_since_last_sale'] = delta.dt.days.fillna(999).astype(int)\n",
        "\n",
        "    # 보조 컬럼 정리\n",
        "    df = df.drop(columns=['last_pos_date'])\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "aUtmAf6TW7BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df = dataPreProcessing(train)\n",
        "train_feat = add_ts_features(train_df)\n",
        "\n",
        "train_feat = add_days_since_last_sale(train_feat)\n",
        "train_df"
      ],
      "metadata": {
        "id": "WKdBtwjDTXoT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "1232972a-992f-400b-d0d9-824610e2b908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        date_time         market_menu  sales_amount  weekday  weekend  month  \\\n",
              "0      2023-01-01  느티나무 셀프BBQ_1인 수저세트             0        6        1      1   \n",
              "1      2023-01-02  느티나무 셀프BBQ_1인 수저세트             0        0        0      1   \n",
              "2      2023-01-03  느티나무 셀프BBQ_1인 수저세트             0        1        0      1   \n",
              "3      2023-01-04  느티나무 셀프BBQ_1인 수저세트             0        2        0      1   \n",
              "4      2023-01-05  느티나무 셀프BBQ_1인 수저세트             0        3        0      1   \n",
              "...           ...                 ...           ...      ...      ...    ...   \n",
              "102671 2024-06-11        화담숲카페_현미뻥스크림            12        1        0      6   \n",
              "102672 2024-06-12        화담숲카페_현미뻥스크림            10        2        0      6   \n",
              "102673 2024-06-13        화담숲카페_현미뻥스크림            14        3        0      6   \n",
              "102674 2024-06-14        화담숲카페_현미뻥스크림            12        4        0      6   \n",
              "102675 2024-06-15        화담숲카페_현미뻥스크림            60        5        1      6   \n",
              "\n",
              "        dayofweek  day  holiday  vacation_season  store_name menu_name  \\\n",
              "0               6    1        1                1  느티나무 셀프BBQ   1인 수저세트   \n",
              "1               0    2        0                1  느티나무 셀프BBQ   1인 수저세트   \n",
              "2               1    3        0                1  느티나무 셀프BBQ   1인 수저세트   \n",
              "3               2    4        0                1  느티나무 셀프BBQ   1인 수저세트   \n",
              "4               3    5        0                1  느티나무 셀프BBQ   1인 수저세트   \n",
              "...           ...  ...      ...              ...         ...       ...   \n",
              "102671          1   11        0                0       화담숲카페    현미뻥스크림   \n",
              "102672          2   12        0                0       화담숲카페    현미뻥스크림   \n",
              "102673          3   13        0                0       화담숲카페    현미뻥스크림   \n",
              "102674          4   14        0                0       화담숲카페    현미뻥스크림   \n",
              "102675          5   15        0                0       화담숲카페    현미뻥스크림   \n",
              "\n",
              "       usage_type  is_premium  usage_type_encoded  \n",
              "0              단체           0                   2  \n",
              "1              단체           0                   2  \n",
              "2              단체           0                   2  \n",
              "3              단체           0                   2  \n",
              "4              단체           0                   2  \n",
              "...           ...         ...                 ...  \n",
              "102671         일반           0                   4  \n",
              "102672         일반           0                   4  \n",
              "102673         일반           0                   4  \n",
              "102674         일반           0                   4  \n",
              "102675         일반           0                   4  \n",
              "\n",
              "[102676 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5b8af83-416b-49a5-9bab-5a32b4c457fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_time</th>\n",
              "      <th>market_menu</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>weekday</th>\n",
              "      <th>weekend</th>\n",
              "      <th>month</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>day</th>\n",
              "      <th>holiday</th>\n",
              "      <th>vacation_season</th>\n",
              "      <th>store_name</th>\n",
              "      <th>menu_name</th>\n",
              "      <th>usage_type</th>\n",
              "      <th>is_premium</th>\n",
              "      <th>usage_type_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>느티나무 셀프BBQ</td>\n",
              "      <td>1인 수저세트</td>\n",
              "      <td>단체</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-01-02</td>\n",
              "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>느티나무 셀프BBQ</td>\n",
              "      <td>1인 수저세트</td>\n",
              "      <td>단체</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>느티나무 셀프BBQ</td>\n",
              "      <td>1인 수저세트</td>\n",
              "      <td>단체</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>느티나무 셀프BBQ</td>\n",
              "      <td>1인 수저세트</td>\n",
              "      <td>단체</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>느티나무 셀프BBQ</td>\n",
              "      <td>1인 수저세트</td>\n",
              "      <td>단체</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102671</th>\n",
              "      <td>2024-06-11</td>\n",
              "      <td>화담숲카페_현미뻥스크림</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>화담숲카페</td>\n",
              "      <td>현미뻥스크림</td>\n",
              "      <td>일반</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102672</th>\n",
              "      <td>2024-06-12</td>\n",
              "      <td>화담숲카페_현미뻥스크림</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>화담숲카페</td>\n",
              "      <td>현미뻥스크림</td>\n",
              "      <td>일반</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102673</th>\n",
              "      <td>2024-06-13</td>\n",
              "      <td>화담숲카페_현미뻥스크림</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>화담숲카페</td>\n",
              "      <td>현미뻥스크림</td>\n",
              "      <td>일반</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102674</th>\n",
              "      <td>2024-06-14</td>\n",
              "      <td>화담숲카페_현미뻥스크림</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>화담숲카페</td>\n",
              "      <td>현미뻥스크림</td>\n",
              "      <td>일반</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102675</th>\n",
              "      <td>2024-06-15</td>\n",
              "      <td>화담숲카페_현미뻥스크림</td>\n",
              "      <td>60</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>화담숲카페</td>\n",
              "      <td>현미뻥스크림</td>\n",
              "      <td>일반</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102676 rows × 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5b8af83-416b-49a5-9bab-5a32b4c457fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5b8af83-416b-49a5-9bab-5a32b4c457fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5b8af83-416b-49a5-9bab-5a32b4c457fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a7e84b40-ae44-4e02-84a3-6d45905d2de1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7e84b40-ae44-4e02-84a3-6d45905d2de1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a7e84b40-ae44-4e02-84a3-6d45905d2de1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f5355023-234e-4b08-976c-002dc55c4a33\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f5355023-234e-4b08-976c-002dc55c4a33 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#market_menu별로 시계열 순서를 유지한 채로, 마지막 N일을 validation set으로 떼어냄\n",
        "def time_series_train_val_split(df, val_days=7):\n",
        "\n",
        "    train_list = []\n",
        "    val_list = []\n",
        "\n",
        "    for menu, group in df.groupby('market_menu'):\n",
        "        group = group.sort_values('date_time')\n",
        "        if len(group) <= val_days:\n",
        "            train_list.append(group)\n",
        "            continue\n",
        "\n",
        "        train_group = group.iloc[:-val_days]\n",
        "        val_group = group.iloc[-val_days:]\n",
        "\n",
        "        train_list.append(train_group)\n",
        "        val_list.append(val_group)\n",
        "\n",
        "    train_df = pd.concat(train_list)\n",
        "    val_df = pd.concat(val_list)\n",
        "    return train_df, val_df\n"
      ],
      "metadata": {
        "id": "81zji3NdC9fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['sales_amount'] = (\n",
        "    pd.to_numeric(train_df['sales_amount'], errors='coerce')\n",
        "      .fillna(0)\n",
        "      .clip(lower=0)\n",
        ")"
      ],
      "metadata": {
        "id": "FPUjTyFqZaUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['weekend','holiday','vacation_season','usage_type_encoded',\n",
        "                'is_premium','lag_1','lag_7','lag_14','rolling_mean_7','rolling_std_7','days_since_last_sale']\n",
        "\n",
        "\n",
        "train_split, val_split = time_series_train_val_split(train_feat, val_days=7)\n",
        "\n",
        "# ← 여기서 모델 정의 + 학습\n",
        "model = XGBRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(train_split[feature_cols], train_split['sales_amount'])\n",
        "\n",
        "y_pred = model.predict(val_split[feature_cols])\n",
        "print(f\"Validation SMAPE: {smape(val_split['sales_amount'], y_pred):.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7WJBVe74Dlu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbaa1dc-dba1-429e-e7e2-410f9c2fea82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation SMAPE: 138.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#최근 데이터 순서와 기간을 고려\n",
        "def time_series_local_cv(df, feature_cols, n_splits=5, val_days=7):\n",
        "    df = df.sort_values(['market_menu', 'date_time'])\n",
        "    smape_scores = []\n",
        "\n",
        "    unique_dates = sorted(df['date_time'].unique())\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        split_point = unique_dates[-(val_days * (i + 1))]\n",
        "\n",
        "        train_split = df[df['date_time'] < split_point]\n",
        "        val_split = df[(df['date_time'] >= split_point) &\n",
        "                       (df['date_time'] < split_point + pd.Timedelta(days=val_days))]\n",
        "\n",
        "        model = XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42)\n",
        "        model.fit(train_split[feature_cols], train_split['sales_amount'])\n",
        "\n",
        "        y_pred = model.predict(val_split[feature_cols])\n",
        "        score = smape(val_split['sales_amount'], y_pred)\n",
        "        smape_scores.append(score)\n",
        "\n",
        "        print(f\"Fold {i+1} | Validation Date from {split_point.date()} → SMAPE: {score:.2f}\")\n",
        "\n",
        "    avg_score = np.mean(smape_scores)\n",
        "    print(f\"\\n📊 Average Local CV SMAPE (n={n_splits} folds): {avg_score:.2f}\")\n",
        "    return smape_scores\n"
      ],
      "metadata": {
        "id": "rFp_4mNuFQHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Local CV\n",
        "time_series_local_cv(train_feat, feature_cols, n_splits=5, val_days=7)"
      ],
      "metadata": {
        "id": "cEnTocy5FV38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404fda17-2575-421f-d6ad-487448062a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 | Validation Date from 2024-06-09 → SMAPE: 140.34\n",
            "Fold 2 | Validation Date from 2024-06-02 → SMAPE: 132.85\n",
            "Fold 3 | Validation Date from 2024-05-26 → SMAPE: 135.35\n",
            "Fold 4 | Validation Date from 2024-05-19 → SMAPE: 129.40\n",
            "Fold 5 | Validation Date from 2024-05-12 → SMAPE: 132.79\n",
            "\n",
            "📊 Average Local CV SMAPE (n=5 folds): 134.15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(140.34055895783737),\n",
              " np.float64(132.85075417186223),\n",
              " np.float64(135.34844496133425),\n",
              " np.float64(129.4039144348293),\n",
              " np.float64(132.7859433018116)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ],
      "metadata": {
        "id": "E4c8pBKkG4Nh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "I2aoxBRCG5ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "4Hp7H3WzG7S8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "sHXYrHOyHEfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "WYIBpgo7G8m8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "FkI6JV21HdWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gagyeomkim"
      ],
      "metadata": {
        "id": "JvCVomTDZzVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KGY"
      ],
      "metadata": {
        "id": "5PvM_N-ALaVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: 예측\n",
        "y_pred = model.predict(val_split[feature_cols])\n",
        "\n",
        "# 성능 평가 (SMAPE 사용)\n",
        "score = smape(val_split['sales_amount'], y_pred)\n",
        "print(f\"Validation SMAPE: {score:.2f}\")\n"
      ],
      "metadata": {
        "id": "i_vO5KGDLhcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd827d7f-3a4e-44b4-d815-5116a815340c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation SMAPE: 138.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_test_features(train_df, raw_test_df, lags=(1,7,14), roll_window=7):\n",
        "    # 1) 공통 전처리(한글→영문 리네임, 캘린더 파생 등)\n",
        "    T = dataPreProcessing(raw_test_df).copy()\n",
        "\n",
        "    # 2) test 28일에 실제 매출이 있으면 그대로 사용 (없으면 0으로 대체)\n",
        "    if 'sales_amount' not in T.columns:\n",
        "        T['sales_amount'] = 0.0\n",
        "\n",
        "    combo = T.sort_values(['market_menu','date_time'])\n",
        "    combo = add_ts_features(combo, lags=lags, roll_window=roll_window)\n",
        "    combo = add_days_since_last_sale(combo)\n",
        "\n",
        "    feat_test = combo[combo['date_time'].isin(T['date_time']) &\n",
        "                      (combo['market_menu'].isin(T['market_menu']))].copy()\n",
        "    return feat_test\n",
        "\n"
      ],
      "metadata": {
        "id": "Gt2fXCtYLnSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def block_cv_28to7(df_prepped, feature_cols, n_folds=5, ctx_days=28, horizon=7, gap=0):\n",
        "    \"\"\"\n",
        "    [컨텍스트 28일] → [다음 7일]을 누수 없이 자동회귀 롤아웃으로 검증\n",
        "    - 컨텍스트 28일만 입력으로 사용 (train tail 사용 금지)\n",
        "    - 검증 7일의 실제값은 피처 계산에 사용하지 않음 (teacher forcing 금지)\n",
        "    \"\"\"\n",
        "    df_prepped = df_prepped.sort_values(['market_menu','date_time']).copy()\n",
        "    uniq = np.array(sorted(df_prepped['date_time'].unique()))\n",
        "    scores = []\n",
        "\n",
        "    for i in range(1, n_folds+1):\n",
        "        need = ctx_days + horizon + gap\n",
        "        if len(uniq) < need * i:\n",
        "            break\n",
        "\n",
        "        s = uniq[-need * i]  # 컨텍스트 시작일\n",
        "        ctx_start, ctx_end = s, s + pd.Timedelta(days=ctx_days-1)\n",
        "        val_start = ctx_end + pd.Timedelta(days=1+gap)\n",
        "        val_end   = val_start + pd.Timedelta(days=horizon-1)\n",
        "\n",
        "        # -------------------------\n",
        "        # 1) 학습: 컨텍스트 시작 이전만\n",
        "        # -------------------------\n",
        "        train_part = df_prepped[df_prepped['date_time'] < ctx_start].copy()\n",
        "        tr_feat  = add_ts_features(train_part)\n",
        "        tr_feat  = add_days_since_last_sale(tr_feat)\n",
        "        tr_feat['sales_amount'] = pd.to_numeric(tr_feat['sales_amount'], errors='coerce').fillna(0).clip(lower=0)\n",
        "\n",
        "        model = XGBRegressor(\n",
        "            n_estimators=600, max_depth=6, learning_rate=0.05,\n",
        "            subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1\n",
        "        )\n",
        "        model.fit(tr_feat[feature_cols], tr_feat['sales_amount'])\n",
        "\n",
        "        # -------------------------\n",
        "        # 2) 추론: 컨텍스트 28일만 사용\n",
        "        # -------------------------\n",
        "        ctx_only = df_prepped[(df_prepped['date_time'] >= ctx_start) &\n",
        "                              (df_prepped['date_time'] <= ctx_end)].copy()\n",
        "\n",
        "        # 컨텍스트로 피처 생성\n",
        "        combo = ctx_only.sort_values(['market_menu','date_time']).copy()\n",
        "        combo = add_ts_features(combo)\n",
        "        combo = add_days_since_last_sale(combo)\n",
        "\n",
        "        # 검증 정답(비교용) — 피처엔 사용 금지\n",
        "        val_truth = df_prepped[(df_prepped['date_time'] >= val_start) &\n",
        "                               (df_prepped['date_time'] <= val_end)][['market_menu','date_time','sales_amount']].copy()\n",
        "\n",
        "        # 예측할 메뉴 집합(컨텍스트∩검증 교집합이 안전)\n",
        "        menus = sorted(set(combo['market_menu']) & set(val_truth['market_menu']))\n",
        "\n",
        "        preds = []\n",
        "        for h in range(horizon):\n",
        "            fut_date = val_start + pd.Timedelta(days=h)\n",
        "\n",
        "            # 미래 하루 행 생성(매뉴별), 캘린더/도메인 파생 붙이기\n",
        "            fut = pd.DataFrame({\n",
        "                'date_time': [fut_date]*len(menus),\n",
        "                'market_menu': menus,\n",
        "                'sales_amount': 0.0\n",
        "            })\n",
        "            fut = dataPreProcessing(fut)[[\n",
        "                'date_time','market_menu','sales_amount',\n",
        "                'weekend','holiday','vacation_season',\n",
        "                'usage_type_encoded','is_premium'\n",
        "            ]]\n",
        "\n",
        "            # 컨텍스트 + 지금까지의 예측을 가진 combo에 이어붙이고 피처 갱신\n",
        "            combo = pd.concat([combo, fut], ignore_index=True, sort=False)\n",
        "            combo = combo.sort_values(['market_menu','date_time'])\n",
        "            combo = add_ts_features(combo)\n",
        "            combo = add_days_since_last_sale(combo)\n",
        "\n",
        "            mask = combo['date_time'].eq(fut_date)\n",
        "            Xf = (combo.loc[mask, feature_cols]\n",
        "                        .apply(pd.to_numeric, errors='coerce')\n",
        "                        .fillna(0).astype(float))\n",
        "            y_hat = model.predict(Xf).clip(0)\n",
        "\n",
        "            # 다음 step을 위해 예측값을 기록(teacher forcing 방지)\n",
        "            combo.loc[mask, 'sales_amount'] = y_hat\n",
        "\n",
        "            preds.append(pd.DataFrame({\n",
        "                'market_menu': combo.loc[mask, 'market_menu'].values,\n",
        "                'date_time': fut_date,\n",
        "                'pred': y_hat\n",
        "            }))\n",
        "\n",
        "        pred_df = pd.concat(preds, ignore_index=True)\n",
        "        merged = val_truth.merge(pred_df, on=['market_menu','date_time'], how='left')\n",
        "        merged['pred'] = merged['pred'].fillna(0.0)\n",
        "\n",
        "        s_score = smape(merged['sales_amount'].to_numpy(), merged['pred'].to_numpy())\n",
        "        print(f\"Fold{i}: ctx {ctx_start.date()}~{ctx_end.date()} → val {val_start.date()}~{val_end.date()} | SMAPE {s_score:.4f}\")\n",
        "        scores.append(s_score)\n",
        "\n",
        "    if scores:\n",
        "        print(\"Avg SMAPE:\", np.mean(scores))\n",
        "    return scores\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-J8vqtcBUXLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def block_cv_28to7_2stage(\n",
        "    df_prepped, feature_cols, n_folds=5, ctx_days=28, horizon=7, gap=0,\n",
        "    tau_grid=(0.3, 0.4, 0.5, 0.6), default_tau=0.5,\n",
        "    calibrate=False,          # Platt calibration 적용 여부\n",
        "    use_soft=True,            # soft 게이팅(p_pos**alpha) 사용 여부\n",
        "    alpha=0.35                # soft 게이팅 지수\n",
        "):\n",
        "    \"\"\"\n",
        "    [컨텍스트 28일] → [다음 7일] 자동회귀 롤아웃 CV (누수 없음).\n",
        "    - 컨텍스트 28일만 입력 사용 (train tail/미래 실제값 금지)\n",
        "    - use_soft=True면 최종 스코어도 soft 방식으로 계산\n",
        "    \"\"\"\n",
        "    df_prepped = df_prepped.sort_values(['market_menu','date_time']).copy()\n",
        "    uniq = np.array(sorted(df_prepped['date_time'].unique()))\n",
        "    scores = []\n",
        "\n",
        "    for i in range(1, n_folds+1):\n",
        "        need = ctx_days + horizon + gap\n",
        "        if len(uniq) < need * i:\n",
        "            break\n",
        "\n",
        "        s = uniq[-need * i]\n",
        "        ctx_start, ctx_end = s, s + pd.Timedelta(days=ctx_days-1)\n",
        "        val_start = ctx_end + pd.Timedelta(days=1+gap)\n",
        "        val_end   = val_start + pd.Timedelta(days=horizon-1)\n",
        "\n",
        "        # -------------------------\n",
        "        # 1) 학습: 컨텍스트 시작 이전만\n",
        "        # -------------------------\n",
        "        train_part = df_prepped[df_prepped['date_time'] < ctx_start].copy()\n",
        "        tr_feat = add_ts_features(train_part)\n",
        "        tr_feat = add_days_since_last_sale(tr_feat)\n",
        "\n",
        "        y = (pd.to_numeric(tr_feat['sales_amount'], errors='coerce')\n",
        "               .fillna(0).clip(lower=0).to_numpy())\n",
        "        X_tr = (tr_feat[feature_cols]\n",
        "                .apply(pd.to_numeric, errors='coerce')\n",
        "                .fillna(0).astype(float))\n",
        "\n",
        "        # 분류기(base) → (옵션) Platt 보정 → proba 함수\n",
        "        pos_rate = (y > 0).mean()\n",
        "        neg_pos  = (1 - pos_rate) / max(pos_rate, 1e-6)\n",
        "\n",
        "        clf_base = XGBClassifier(\n",
        "            n_estimators=500, max_depth=6, learning_rate=0.05,\n",
        "            subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1,\n",
        "            scale_pos_weight=neg_pos\n",
        "        )\n",
        "        clf_base.fit(X_tr, (y > 0).astype(int))\n",
        "\n",
        "        if calibrate:\n",
        "            cal = CalibratedClassifierCV(clf_base, method='sigmoid', cv=3)\n",
        "            cal.fit(X_tr, (y > 0).astype(int))\n",
        "            proba = lambda X: cal.predict_proba(\n",
        "                X.apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "            )[:, 1]\n",
        "        else:\n",
        "            proba = lambda X: clf_base.predict_proba(\n",
        "                X.apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "            )[:, 1]\n",
        "\n",
        "        # 회귀기\n",
        "        w = 1.0 / (1.0 + y)\n",
        "        t = np.log1p(y)\n",
        "        reg = XGBRegressor(\n",
        "            n_estimators=800, max_depth=7, learning_rate=0.04,\n",
        "            subsample=0.8, colsample_bytree=0.9, random_state=42, n_jobs=-1\n",
        "        )\n",
        "        reg.fit(X_tr, t, sample_weight=w)\n",
        "\n",
        "        # -------------------------\n",
        "        # 2) 추론: 컨텍스트 28일만 사용 (오토리그레시브 롤아웃)\n",
        "        # -------------------------\n",
        "        ctx_only = df_prepped[(df_prepped['date_time'] >= ctx_start) &\n",
        "                              (df_prepped['date_time'] <= ctx_end)].copy()\n",
        "\n",
        "        combo = ctx_only.sort_values(['market_menu','date_time']).copy()\n",
        "        combo = add_ts_features(combo)\n",
        "        combo = add_days_since_last_sale(combo)\n",
        "\n",
        "        val_truth = df_prepped[(df_prepped['date_time'] >= val_start) &\n",
        "                               (df_prepped['date_time'] <= val_end)][['market_menu','date_time','sales_amount']].copy()\n",
        "        menus = sorted(set(combo['market_menu']) & set(val_truth['market_menu']))\n",
        "\n",
        "        rows = []\n",
        "        for h in range(horizon):\n",
        "            fut_date = val_start + pd.Timedelta(days=h)\n",
        "\n",
        "            fut = pd.DataFrame({\n",
        "                'date_time': [fut_date]*len(menus),\n",
        "                'market_menu': menus,\n",
        "                'sales_amount': 0.0\n",
        "            })\n",
        "            fut = dataPreProcessing(fut)[[\n",
        "                'date_time','market_menu','sales_amount',\n",
        "                'weekend','holiday','vacation_season',\n",
        "                'usage_type_encoded','is_premium'\n",
        "            ]]\n",
        "\n",
        "            combo = pd.concat([combo, fut], ignore_index=True, sort=False)\n",
        "            combo = combo.sort_values(['market_menu','date_time'])\n",
        "            combo = add_ts_features(combo)\n",
        "            combo = add_days_since_last_sale(combo)\n",
        "\n",
        "            mask = combo['date_time'].eq(fut_date)\n",
        "            Xf = (combo.loc[mask, feature_cols]\n",
        "                        .apply(pd.to_numeric, errors='coerce')\n",
        "                        .fillna(0).astype(float))\n",
        "\n",
        "            p_pos = proba(Xf)\n",
        "            y_hat = np.expm1(reg.predict(Xf))\n",
        "            y_hat = np.nan_to_num(y_hat, nan=0.0, posinf=0.0, neginf=0.0).clip(0)\n",
        "\n",
        "            # 롤아웃용 기록값\n",
        "            if use_soft:\n",
        "                y_for_next = (y_hat * np.power(p_pos, alpha)).clip(0)\n",
        "            else:\n",
        "                y_for_next = y_hat\n",
        "\n",
        "            combo.loc[mask, 'sales_amount'] = y_for_next\n",
        "\n",
        "            rows.append(pd.DataFrame({\n",
        "                'market_menu': combo.loc[mask, 'market_menu'].values,\n",
        "                'date_time': fut_date,\n",
        "                'p': p_pos,\n",
        "                'yhat': y_hat\n",
        "            }))\n",
        "\n",
        "        preds_df = pd.concat(rows, ignore_index=True)\n",
        "        merged = val_truth.merge(preds_df, on=['market_menu','date_time'], how='left')\n",
        "        merged['yhat'] = merged['yhat'].fillna(0.0)\n",
        "        merged['p']    = merged['p'].fillna(0.0)\n",
        "\n",
        "        # -------------------------\n",
        "        # 3) 최종 예측: soft vs hard\n",
        "        # -------------------------\n",
        "        if use_soft:\n",
        "            final_pred = (merged['yhat'].to_numpy() * np.power(merged['p'].to_numpy(), alpha)).clip(0)\n",
        "        else:\n",
        "            # hard: per-menu τ 탐색\n",
        "            best_tau = {}\n",
        "            for menu, g in merged.groupby('market_menu'):\n",
        "                y_true = g['sales_amount'].to_numpy()\n",
        "                p      = g['p'].to_numpy()\n",
        "                yhat   = g['yhat'].to_numpy()\n",
        "                best_s, best_t = 1e9, default_tau\n",
        "                for t_ in tau_grid:\n",
        "                    pred_ = np.where(p < t_, 0.0, yhat).clip(0)\n",
        "                    s_ = smape(y_true, pred_)\n",
        "                    if s_ < best_s:\n",
        "                        best_s, best_t = s_, t_\n",
        "                best_tau[menu] = best_t\n",
        "\n",
        "            taus = merged['market_menu'].map(best_tau).fillna(default_tau).to_numpy()\n",
        "            final_pred = np.where(merged['p'].to_numpy() < taus, 0.0, merged['yhat'].to_numpy()).clip(0)\n",
        "\n",
        "        s_score = smape(merged['sales_amount'].to_numpy(), final_pred)\n",
        "        print(f\"[2stage NL] Fold{i}: ctx {ctx_start.date()}~{ctx_end.date()} → val {val_start.date()}~{val_end.date()} | SMAPE {s_score:.4f}\")\n",
        "        scores.append(s_score)\n",
        "\n",
        "    if scores:\n",
        "        print(\"Avg SMAPE (2-stage, no-leak):\", np.mean(scores))\n",
        "    return scores\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Al9WKfYSXOKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Block CV (28→7, gap=0) / 1-stage ===\")\n",
        "_ = block_cv_28to7(train_df, feature_cols, n_folds=5, ctx_days=28, horizon=7, gap=0)\n",
        "\n",
        "print(\"\\n=== Block CV (28→7, gap=0) / 2-stage ===\")\n",
        "_ = block_cv_28to7_2stage(train_df, feature_cols, n_folds=5, ctx_days=28, horizon=7, gap=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKbVfTJ2Ur__",
        "outputId": "c1df35fb-d9a0-41c8-9b52-764723f37d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Block CV (28→7, gap=0) / 1-stage ===\n",
            "Fold1: ctx 2024-05-12~2024-06-08 → val 2024-06-09~2024-06-15 | SMAPE 110.9638\n",
            "Fold2: ctx 2024-04-07~2024-05-04 → val 2024-05-05~2024-05-11 | SMAPE 135.8765\n",
            "Fold3: ctx 2024-03-03~2024-03-30 → val 2024-03-31~2024-04-06 | SMAPE 123.2955\n",
            "Fold4: ctx 2024-01-28~2024-02-24 → val 2024-02-25~2024-03-02 | SMAPE 129.9081\n",
            "Fold5: ctx 2023-12-24~2024-01-20 → val 2024-01-21~2024-01-27 | SMAPE 124.5387\n",
            "Avg SMAPE: 124.91651477793069\n",
            "\n",
            "=== Block CV (28→7, gap=0) / 2-stage ===\n",
            "[2stage NL] Fold1: ctx 2024-05-12~2024-06-08 → val 2024-06-09~2024-06-15 | SMAPE 128.0442\n",
            "[2stage NL] Fold2: ctx 2024-04-07~2024-05-04 → val 2024-05-05~2024-05-11 | SMAPE 138.9935\n",
            "[2stage NL] Fold3: ctx 2024-03-03~2024-03-30 → val 2024-03-31~2024-04-06 | SMAPE 141.2198\n",
            "[2stage NL] Fold4: ctx 2024-01-28~2024-02-24 → val 2024-02-25~2024-03-02 | SMAPE 142.1096\n",
            "[2stage NL] Fold5: ctx 2023-12-24~2024-01-20 → val 2024-01-21~2024-01-27 | SMAPE 145.6584\n",
            "Avg SMAPE (2-stage, no-leak): 139.20511671811693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forecast_next7_for_block(\n",
        "    train_df,\n",
        "    raw_test_df,\n",
        "    feature_cols,\n",
        "    clf,\n",
        "    reg,\n",
        "    tau_by_menu=None,          # hard 모드에서만 사용\n",
        "    default_tau=0.35,          # hard 모드의 기본 τ (off는 <0), soft 모드에선 무시\n",
        "    block_id=\"TEST_XX\",\n",
        "    gate_mode=\"soft\",          # \"soft\"(기본) | \"hard\" | \"off\"\n",
        "    alpha=0.30,\n",
        "    prob_gamma=0.6,            # soft 게이팅 지수: y_final = y_hat * p_pos**alpha\n",
        "    tau_floor_prob=0.0,       # p_pos가 이보다 작으면 floor 미적용\n",
        "    floor_ratio=0.12,          # floor = (컨텍스트 양수 평균)*floor_ratio\n",
        "    scale_clip=(0.8, 12.0),     # 컨텍스트 스케일 클리핑 범위\n",
        "    apply_scale=True,\n",
        "    apply_floor=True\n",
        "):\n",
        "    \"\"\"\n",
        "    반환: DataFrame[token, 영업장명_메뉴명, 매출수량]  (+1~+7일)\n",
        "    전제: dataPreProcessing, add_ts_features, add_days_since_last_sale가 이미 정의되어 있음.\n",
        "    \"\"\"\n",
        "\n",
        "    # 0) 컨텍스트 28일 준비\n",
        "    T = dataPreProcessing(raw_test_df).copy()\n",
        "    if 'sales_amount' not in T.columns:\n",
        "        T['sales_amount'] = 0.0\n",
        "\n",
        "     # 컨텍스트만으로 파생\n",
        "    combo = T.sort_values(['market_menu','date_time']).copy()\n",
        "    combo = add_ts_features(combo)\n",
        "    combo = add_days_since_last_sale(combo)\n",
        "\n",
        "    preds = []\n",
        "    ctx_last = combo['date_time'].max()\n",
        "    ctx_start = ctx_last - pd.Timedelta(days=27)   # 28일 창\n",
        "    menus = T['market_menu'].drop_duplicates().tolist()\n",
        "\n",
        "    # 1) 컨텍스트 기반 보정량 계산 (soft 모드용)\n",
        "    #    - 메뉴별 floor(양수 평균*ratio)\n",
        "    #    - 최근 7일 실제합/예측합 비율로 scale\n",
        "    floor_map, scale_by_menu = {}, {}\n",
        "    if gate_mode == \"soft\":\n",
        "        # (A) floor\n",
        "        ctx_hist = combo[(combo['date_time'] >= ctx_start) & (combo['date_time'] <= ctx_last)].copy()\n",
        "        q = 0.45\n",
        "        pos_q = (ctx_hist[ctx_hist['sales_amount'] > 0]\n",
        "             .groupby('market_menu')['sales_amount']\n",
        "             .quantile(q).fillna(0.0))\n",
        "        floor_map = (floor_ratio * pos_q).to_dict() if apply_floor else {}\n",
        "\n",
        "        # (B) scale (최근 7일)\n",
        "        ctx7_mask = combo['date_time'].between(ctx_last - pd.Timedelta(days=6), ctx_last)\n",
        "        scale_by_menu = {}\n",
        "        if ctx7_mask.any():\n",
        "            X_ctx7 = (ctx_hist.loc[ctx7_mask, feature_cols]\n",
        "                  .apply(pd.to_numeric, errors='coerce').fillna(0).astype(float))\n",
        "            y_ctx7_hat = np.expm1(reg.predict(X_ctx7))\n",
        "            y_ctx7_hat = np.nan_to_num(y_ctx7_hat, nan=0.0, posinf=0.0, neginf=0.0).clip(0)\n",
        "\n",
        "            hat_sum_by_menu = pd.Series(y_ctx7_hat,\n",
        "                                    index=ctx_hist.loc[ctx7_mask, 'market_menu']).groupby(level=0).sum()\n",
        "            true_sum_by_menu = ctx_hist.loc[ctx7_mask].groupby('market_menu')['sales_amount'].sum()\n",
        "            scale_series = (true_sum_by_menu / (hat_sum_by_menu + 1e-6)).fillna(1.0)\n",
        "            global_scale = float(true_sum_by_menu.sum() / (hat_sum_by_menu.sum() + 1e-6))\n",
        "            scale_series = 0.5*scale_series + 0.5*global_scale\n",
        "            if apply_scale:\n",
        "                scale_series = scale_series.clip(lower=0.8, upper=12.0)\n",
        "                scale_by_menu = scale_series.to_dict()\n",
        "            else:\n",
        "                scale_by_menu = {k: 1.0 for k in true_sum_by_menu.index}\n",
        "\n",
        "    # 2) 7-step 롤아웃\n",
        "    for h in range(1, 8):\n",
        "        fut_date = ctx_last + pd.Timedelta(days=h)\n",
        "        # 미래 한 줄(각 메뉴) 생성 + 공통 파생\n",
        "        fut = pd.DataFrame({\n",
        "            'date_time': [fut_date]*len(menus),\n",
        "            'market_menu': menus,\n",
        "            'sales_amount': 0.0\n",
        "        })\n",
        "        fut = dataPreProcessing(fut)[[\n",
        "            'date_time','market_menu','sales_amount',\n",
        "            'weekend','holiday','vacation_season',\n",
        "            'usage_type_encoded','is_premium','store_name','menu_name'\n",
        "        ]]\n",
        "\n",
        "        # 컨테이너에 붙여 동일 피처 생성\n",
        "        combo = pd.concat([combo, fut], ignore_index=True, sort=False)\n",
        "        combo = combo.sort_values(['market_menu','date_time'])\n",
        "        combo = add_ts_features(combo)\n",
        "        combo = add_days_since_last_sale(combo)\n",
        "\n",
        "        # 방금 추가한 미래행만 예측\n",
        "        mask = (combo['date_time'] == fut_date)\n",
        "        Xf = combo.loc[mask, feature_cols].copy()\n",
        "        Xf = Xf.apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "\n",
        "        p_pos = clf.predict_proba(Xf)[:, 1]\n",
        "        # 선택: 확률 팽창(작을수록 덜 깎이게 함)\n",
        "        if prob_gamma is not None and prob_gamma != 1.0:\n",
        "            p_pos = 1.0 - np.power(1.0 - p_pos, prob_gamma)\n",
        "        y_hat = np.expm1(reg.predict(Xf))\n",
        "        y_hat = np.nan_to_num(y_hat, nan=0.0, posinf=0.0, neginf=0.0).clip(0)\n",
        "\n",
        "        if gate_mode == \"off\" or (default_tau is not None and default_tau < 0):\n",
        "            # 게이팅 완전 OFF\n",
        "            y_final = y_hat.copy()\n",
        "\n",
        "        elif gate_mode == \"hard\":\n",
        "            # 하드 게이팅 (기존 방식 유지 옵션)\n",
        "            if tau_by_menu is None:\n",
        "                tau_vec = np.full(len(Xf), (default_tau if default_tau is not None else 0.35))\n",
        "            else:\n",
        "                tau_vec = np.array([\n",
        "                    tau_by_menu.get(m, (default_tau if default_tau is not None else 0.35))\n",
        "                    for m in combo.loc[mask, 'market_menu']\n",
        "                ])\n",
        "            y_final = np.where(p_pos < tau_vec, 0.0, y_hat).clip(0)\n",
        "\n",
        "        else:\n",
        "            # SOFT 게이팅 + 스케일 + 바닥값\n",
        "            # 1) 소프트 게이팅\n",
        "            y_soft = y_hat * np.power(p_pos, (alpha if alpha is not None else 0.0))\n",
        "\n",
        "            # 2) 메뉴별 스케일\n",
        "            if apply_scale and len(scale_by_menu):\n",
        "                s_vec = np.array([scale_by_menu.get(m, 1.0) for m in combo.loc[mask, 'market_menu']])\n",
        "                y_scaled = (y_soft * s_vec).clip(0)\n",
        "            else:\n",
        "                y_scaled = y_soft\n",
        "\n",
        "            # 3) 바닥값 (확률이 너무 낮으면 floor 미적용)\n",
        "            if apply_floor and len(floor_map):\n",
        "                floor_vec = np.array([floor_map.get(m, 0.0) for m in combo.loc[mask, 'market_menu']])\n",
        "                apply_mask = p_pos >= (tau_floor_prob if tau_floor_prob is not None else 0.0)\n",
        "                # p_pos가 너무 낮으면 floor 미적용 → 그대로 y_scaled\n",
        "                y_final = np.where(apply_mask, np.maximum(y_scaled, floor_vec), y_scaled).clip(0)\n",
        "            else:\n",
        "                y_final = y_scaled\n",
        "\n",
        "        ctx_hist = combo[combo['date_time'] <= ctx_last].copy()  # 컨텍스트 28일까지만\n",
        "        dow = fut_date.dayofweek\n",
        "        true_day_sums = (\n",
        "            ctx_hist.assign(dow=ctx_hist['date_time'].dt.dayofweek)\n",
        "                    .query('dow == @dow')\n",
        "                    .groupby('date_time')['sales_amount'].sum()\n",
        "        )\n",
        "        if len(true_day_sums):\n",
        "            target_sum = float(true_day_sums.median())  # 필요시 mean()으로 교체 가능\n",
        "            pred_sum = float(y_final.sum()) + 1e-6\n",
        "            k = np.clip(target_sum / pred_sum, 0.5, 8.0)  # 과도 왜곡 방지\n",
        "            y_final = (y_final * k).clip(0)\n",
        "\n",
        "        # 다음 step의 라그/롤링 반영을 위해 예측값을 combo에 기록\n",
        "        combo.loc[mask, 'sales_amount'] = y_final\n",
        "\n",
        "        # 결과 저장\n",
        "        preds.append(pd.DataFrame({\n",
        "            'token': [f\"{block_id}+{h}일\"] * np.sum(mask),\n",
        "            '영업장명_메뉴명': combo.loc[mask, 'market_menu'].values,\n",
        "            '매출수량': y_final\n",
        "        }))\n",
        "\n",
        "    return pd.concat(preds, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "TBRNbiaaxRK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 train으로 최종 학습\n",
        "tr_feat_full = add_ts_features(train_df)\n",
        "tr_feat_full = add_days_since_last_sale(tr_feat_full)\n",
        "# X/y 정리 (숫자형 강제)\n",
        "Xf_full = tr_feat_full[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "y_full  = (pd.to_numeric(tr_feat_full['sales_amount'], errors='coerce')\n",
        "           .fillna(0).clip(lower=0).to_numpy())\n",
        "\n",
        "# 분류기 (불균형 보정)\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "pos_rate = (y_full > 0).mean()\n",
        "neg_pos  = (1 - pos_rate) / max(pos_rate, 1e-6)\n",
        "\n",
        "clf = XGBClassifier(\n",
        "    n_estimators=600, max_depth=6, learning_rate=0.05,\n",
        "    subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1,\n",
        "    scale_pos_weight=neg_pos\n",
        ")\n",
        "clf.fit(Xf_full, (y_full > 0).astype(int))\n",
        "\n",
        "# 회귀기 (log1p + 가중치)\n",
        "w_full = 1.0 / (1.0 + y_full)\n",
        "reg = XGBRegressor(\n",
        "    n_estimators=900, max_depth=7, learning_rate=0.04,\n",
        "    subsample=0.8, colsample_bytree=0.9, random_state=42, n_jobs=-1\n",
        ")\n",
        "reg.fit(Xf_full, np.log1p(y_full), sample_weight=w_full)\n"
      ],
      "metadata": {
        "id": "3m2p9EmacaSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_tau_by_menu_last_block(train_df, feature_cols, tau_grid=np.arange(0.25, 0.76, 0.05)):\n",
        "    # 마지막 컨텍스트 28일 → 다음 7일을 검증으로 사용\n",
        "    df = train_df.sort_values(['market_menu','date_time']).copy()\n",
        "    uniq = np.array(sorted(df['date_time'].unique()))\n",
        "    ctx_days, horizon = 28, 7\n",
        "    s = uniq[-(ctx_days + horizon)]\n",
        "    ctx_start, ctx_end = s, s + pd.Timedelta(days=ctx_days-1)\n",
        "    val_start = ctx_end + pd.Timedelta(days=1)\n",
        "    val_end   = val_start + pd.Timedelta(days=horizon-1)\n",
        "\n",
        "    train_part = df[df['date_time'] < ctx_start].copy()\n",
        "    tail = train_part.groupby('market_menu', as_index=False).tail(max(28,14,7))\n",
        "    combo = pd.concat([\n",
        "        tail,\n",
        "        df[(df['date_time']>=ctx_start) & (df['date_time']<=ctx_end)],\n",
        "        df[(df['date_time']>=val_start) & (df['date_time']<=val_end)],\n",
        "    ], ignore_index=True, sort=False).sort_values(['market_menu','date_time'])\n",
        "\n",
        "    # 학습\n",
        "    tr_feat = add_ts_features(train_part); tr_feat = add_days_since_last_sale(tr_feat)\n",
        "    X_tr = tr_feat[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "    y    = (pd.to_numeric(tr_feat['sales_amount'], errors='coerce').fillna(0).clip(lower=0).to_numpy())\n",
        "\n",
        "    pos_rate = (y > 0).mean(); neg_pos = (1 - pos_rate) / max(pos_rate, 1e-6)\n",
        "    clf = XGBClassifier(n_estimators=600, max_depth=6, learning_rate=0.05,\n",
        "                        subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1,\n",
        "                        scale_pos_weight=neg_pos)\n",
        "    clf.fit(X_tr, (y>0).astype(int))\n",
        "\n",
        "    w = 1.0/(1.0+y); t = np.log1p(y)\n",
        "    reg = XGBRegressor(n_estimators=900, max_depth=7, learning_rate=0.04,\n",
        "                       subsample=0.8, colsample_bytree=0.9, random_state=42, n_jobs=-1)\n",
        "    reg.fit(X_tr, t, sample_weight=w)\n",
        "\n",
        "    # 검증 블록\n",
        "    combo_ft = add_ts_features(combo); combo_ft = add_days_since_last_sale(combo_ft)\n",
        "    val_block = combo_ft[(combo_ft['date_time']>=val_start)&(combo_ft['date_time']<=val_end)].copy()\n",
        "    X_val = val_block[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
        "    p_pos = clf.predict_proba(X_val)[:,1]\n",
        "    y_hat = np.expm1(reg.predict(X_val)); y_hat = np.nan_to_num(y_hat, nan=0.0, posinf=0.0, neginf=0.0).clip(0)\n",
        "\n",
        "    # 메뉴별 τ 고르기\n",
        "    tau_map = {}\n",
        "    tmp = val_block.assign(p=p_pos, yhat=y_hat)\n",
        "    for menu, g in tmp.groupby('market_menu'):\n",
        "        best_s, best_t = 1e9, 0.5\n",
        "        for t_ in tau_grid:\n",
        "            pred_ = np.where(g['p'].to_numpy() < t_, 0.0, g['yhat'].to_numpy()).clip(0)\n",
        "            s_ = smape(g['sales_amount'].to_numpy(), pred_)\n",
        "            if s_ < best_s:\n",
        "                best_s, best_t = s_, t_\n",
        "        tau_map[menu] = best_t\n",
        "    return tau_map\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w89hCVQF3GTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b4357a-4452-4d4b-dfeb-615077a00f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "τ keys: 1351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tau_by_menu = pick_tau_by_menu_last_block(train_df, feature_cols)\n",
        "print(\"메뉴별 τ 개수:\", len(tau_by_menu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp6zx6Ku3Hx3",
        "outputId": "8338d0e2-a3a4-4f75-da85-bd22bcd772b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "메뉴별 τ 개수: 1351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "Jshgqe-EG-P7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "D0EhDF9THmWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KGY VERSION"
      ],
      "metadata": {
        "id": "9B4l-JdeMZfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# A. 블록별 예측 → full_pred_df (중복 없이 하나로)\n",
        "# ------------------------------------------------------\n",
        "def infer_all_blocks(test_glob_pattern,\n",
        "                     train_df, feature_cols, clf, reg,\n",
        "                     gate_kwargs):\n",
        "    \"\"\"\n",
        "    test_glob_pattern: './test/TEST_*.csv'\n",
        "    gate_kwargs: forecast_next7_for_block에 바로 전달할 게이팅/스케일 kwargs\n",
        "                 (예: {'gate_mode':'soft', 'alpha':0.5, ...})\n",
        "    반환: full_pred_df (token, 영업장명_메뉴명, 매출수량 포함)\n",
        "    \"\"\"\n",
        "    test_files = sorted(glob.glob(test_glob_pattern))\n",
        "    all_preds = []\n",
        "\n",
        "    # tau_by_menu가 있으면 자동 첨부 (있을 때만)\n",
        "    if 'tau_by_menu' not in gate_kwargs:\n",
        "        try:\n",
        "            gate_kwargs = {**gate_kwargs, 'tau_by_menu': tau_by_menu}\n",
        "        except NameError:\n",
        "            pass  # 사용 안 함\n",
        "\n",
        "    for path in test_files:\n",
        "        raw_test = pd.read_csv(path)\n",
        "        block_id = os.path.splitext(os.path.basename(path))[0]  # e.g., TEST_00\n",
        "\n",
        "        pred7 = forecast_next7_for_block(\n",
        "            train_df=train_df,\n",
        "            raw_test_df=raw_test,\n",
        "            feature_cols=feature_cols,\n",
        "            clf=clf, reg=reg,\n",
        "            block_id=block_id,\n",
        "            **gate_kwargs\n",
        "        )\n",
        "        all_preds.append(pred7)\n",
        "\n",
        "    full_pred_df = pd.concat(all_preds, ignore_index=True)\n",
        "    return full_pred_df\n",
        "\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# B. full_pred_df → 제출 DF (벡터화, 조각화 경고 없음)\n",
        "# ------------------------------------------------------\n",
        "def build_submission(full_pred_df, sample_submission_path, save_path=None):\n",
        "    sample_submission = pd.read_csv(sample_submission_path)\n",
        "    sub_tokens = sample_submission['영업일자'].astype(str)\n",
        "    menu_cols = [c for c in sample_submission.columns if c != '영업일자']\n",
        "\n",
        "    # dedup + pivot_table\n",
        "    dedup = (full_pred_df\n",
        "             .groupby(['token','영업장명_메뉴명'], as_index=False)['매출수량']\n",
        "             .sum())\n",
        "    wide_pred = dedup.pivot_table(index='token',\n",
        "                                  columns='영업장명_메뉴명',\n",
        "                                  values='매출수량',\n",
        "                                  aggfunc='sum',\n",
        "                                  fill_value=0.0)\n",
        "\n",
        "    # 순서/컬럼 맞춰 한 번에 생성(조각화 경고 X)\n",
        "    arr = (wide_pred\n",
        "           .reindex(index=sub_tokens, columns=menu_cols, fill_value=0.0)\n",
        "           .astype('float64'))\n",
        "    sub_out = arr.reset_index().rename(columns={'token':'영업일자'})\n",
        "\n",
        "    vals = sub_out[menu_cols].to_numpy(dtype='float64')\n",
        "    print(\"[SUB] sum:\", float(np.nansum(vals)))\n",
        "    print(\"[SUB] nonzero:\", int(np.count_nonzero(vals)))\n",
        "    print(\"[SUB] zero_ratio:\", float((vals == 0).mean()))\n",
        "\n",
        "    if save_path is not None:\n",
        "        os.makedirs(os.path.dirname(save_path) or '.', exist_ok=True)\n",
        "        sub_out.to_csv(save_path, index=False, encoding='utf-8-sig', float_format='%.6f')\n",
        "        print(\"💾 Saved:\", save_path)\n",
        "\n",
        "    return sub_out, wide_pred\n",
        "\n",
        "# ======================================================\n",
        "# 사용 예시\n",
        "#   1) OFF로 스모크 체크 (원인 분리)\n",
        "#   2) ON으로 최종 제출 생성\n",
        "# ======================================================\n",
        "\n",
        "# 1) 게이팅 OFF (진짜 off)\n",
        "RUN_OFF_CHECK = True\n",
        "if RUN_OFF_CHECK:\n",
        "    gate_off = dict(gate_mode='off',\n",
        "                    alpha=0.5,                 # off에서는 무시됨\n",
        "                    tau_floor_prob=0.0,        # 무시됨\n",
        "                    floor_ratio=0.10,          # 무시됨\n",
        "                    scale_clip=(0.5, 6.0),     # 무시됨\n",
        "                    apply_scale=True,\n",
        "                    apply_floor=True)\n",
        "    full_off = infer_all_blocks('./test/TEST_*.csv',\n",
        "                                train_df, feature_cols, clf, reg,\n",
        "                                gate_off)\n",
        "    sub_off, wide_off = build_submission(full_off,\n",
        "                                         './sample_submission.csv',\n",
        "                                         './submission/xgb_off.csv')\n",
        "\n",
        "# 2) 게이팅 ON (소프트 게이팅 추천)\n",
        "gate_on = dict(gate_mode='soft',\n",
        "               alpha=0.30,            # 0.5~0.8 튜닝\n",
        "               tau_floor_prob=0.00,  # floor 항상 허용(값 축소 방지)\n",
        "               floor_ratio=0.15,     # 0.10~0.20 튜닝\n",
        "               scale_clip=(0.8, 12.0),\n",
        "               prob_gamma=0.60,\n",
        "               apply_scale=True,\n",
        "               apply_floor=True)\n",
        "\n",
        "# 예측 후\n",
        "full_pred_df = infer_all_blocks('./test/TEST_*.csv',\n",
        "                                train_df, feature_cols, clf, reg,\n",
        "                                gate_on)  # 혹은 gate_off\n",
        "\n",
        "sub_out, wide_pred = build_submission(full_pred_df, './sample_submission.csv')\n",
        "\n",
        "# ⬇️ 네가 쓰던 저장 스타일 그대로\n",
        "os.makedirs('./submission', exist_ok=True)\n",
        "out_path = './submission/xgb_submission.csv'\n",
        "sub_out.to_csv(out_path, index=False, encoding='utf-8-sig', float_format='%.6f')\n",
        "print(\"✅ 저장 완료 →\", out_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar0WlvllGUXb",
        "outputId": "26bc44d8-eecf-418d-e697-27b0ca25210d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUB] sum: 24270.699296848597\n",
            "[SUB] nonzero: 13510\n",
            "[SUB] zero_ratio: 0.0\n",
            "[SUB] day total min/mean/max: 200.22442292556866 346.72427566926564 615.6228600000005\n",
            "💾 Saved: ./submission/xgb_off.csv\n",
            "[SUB] sum: 38377.58721184859\n",
            "[SUB] nonzero: 13510\n",
            "[SUB] zero_ratio: 0.0\n",
            "[SUB] day total min/mean/max: 256.84000000000003 548.2512458835512 1128.44\n",
            "💾 Saved: ./submission/xgb_submission.csv\n",
            "✅ 저장 완료 → ./submission/xgb_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 제출 빌드 뒤\n",
        "vals = sub_out.iloc[:,1:].to_numpy(dtype='float64')\n",
        "print(\"sum:\", float(np.nansum(vals)))\n",
        "print(\"nonzero:\", int(np.count_nonzero(vals)))\n",
        "print(\"zero_ratio:\", float((vals == 0).mean()))\n",
        "\n",
        "totals = sub_out.iloc[:,1:].sum(axis=1)\n",
        "print(\"day total min/mean/max:\", totals.min(), totals.mean(), totals.max())\n",
        "print(sub_out.iloc[:,1:].sum(axis=0).sort_values(ascending=False).head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17dzCgZLLDkA",
        "outputId": "6b79f4d3-eb45-4c17-f62a-41b0097f4d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sum: 39481.21865\n",
            "nonzero: 10248\n",
            "zero_ratio: 0.24145077720207253\n",
            "day total min/mean/max: 130.8875 564.0174092857144 1265.1630500000012\n",
            "영업장명_메뉴명\n",
            "화담숲주막_해물파전            2805.671963\n",
            "포레스트릿_꼬치어묵            1798.250575\n",
            "카페테리아_단체식 18000(신)    1515.085000\n",
            "미라시아_브런치(대인) 주말       1198.400000\n",
            "카페테리아_단체식 13000(신)    1136.113950\n",
            "연회장_Regular Coffee    1096.049225\n",
            "포레스트릿_떡볶이             1095.447700\n",
            "포레스트릿_생수              1070.093575\n",
            "화담숲카페_아메리카노 ICE        810.083588\n",
            "카페테리아_수제 등심 돈까스        797.683837\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}